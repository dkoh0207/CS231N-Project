{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparse Submanifold Autoencoders\n",
    "\n",
    "### Run this notebook inside a directory that contains dlp_opendata_api folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.14/04\n"
     ]
    }
   ],
   "source": [
    "# Import Dependencies\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "#%matplotlib notebook\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../new_notebooks/ipynb/dlp_opendata_api\")\n",
    "sys.path.append(\"../new_notebooks/ipynb\")\n",
    "from osf.image_api import image_reader_3d\n",
    "from osf.particle_api import *\n",
    "from osf.cluster_api import *\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import sparseconvnet as scn\n",
    "import glob\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ls /gpfs/slac/staas/fs1/g/neutrino/kterao/data/dlprod_ppn_v10\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if CUDA is working (GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'use_cuda' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-068d44368599>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muse_cuda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'use_cuda' is not defined"
     ]
    }
   ],
   "source": [
    "print(use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClusteringAEData(Dataset):\n",
    "    \"\"\"\n",
    "    A customized data loader for clustering.\n",
    "    \"\"\"\n",
    "    def __init__(self, root, numPixels=192, filenames=None):\n",
    "        \"\"\"\n",
    "        Initialize Clustering Dataset\n",
    "\n",
    "        Inputs:\n",
    "            - root: root directory of dataset\n",
    "            - preload: if preload dataset into memory.\n",
    "        \"\"\"\n",
    "        self.cluster_filenames = []\n",
    "        self.energy_filenames = []\n",
    "        self.root = root\n",
    "        self.numPixels = str(numPixels)\n",
    "        \n",
    "        if filenames:\n",
    "            self.energy_filenames = filenames[0]\n",
    "            self.cluster_filenames = filenames[1]\n",
    "            print(self.energy_filenames)\n",
    "\n",
    "        self.energy_filenames.sort()\n",
    "        self.cluster_filenames.sort()\n",
    "        self.cluster_reader = cluster_reader(*self.cluster_filenames)\n",
    "        self.energy_reader = image_reader_3d(*self.energy_filenames)\n",
    "        self.len = self.energy_reader.entry_count()\n",
    "        assert self.len == self.cluster_reader.entry_count()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Get a sample from dataset.\n",
    "        \"\"\"\n",
    "        voxel, label = self.cluster_reader.get_image(index)\n",
    "        _, energy, _ = self.energy_reader.get_image(index)\n",
    "        voxel, label = torch.from_numpy(voxel), torch.from_numpy(label)\n",
    "        energy = torch.from_numpy(energy)\n",
    "        energy = torch.unsqueeze(energy, dim=1)\n",
    "        label = torch.unsqueeze(label, dim=1).type(torch.LongTensor)\n",
    "        return (voxel, energy), label\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Total number of sampels in dataset.\n",
    "        \"\"\"\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ae_collate(batch):\n",
    "    \"\"\"\n",
    "    Custom collate_fn for Autoencoder.\n",
    "    \"\"\"\n",
    "    data = [item[0] for item in batch]\n",
    "    target = [item[1] for item in batch]\n",
    "    return [data, target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Train, Dev, and Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/gpfs/slac/staas/fs1/g/neutrino/kterao/data/dlprod_ppn_v10' #replace with your own path to root folder. \n",
    "trainset_cluster = [root + '/cluster/dlprod_cluster_192px_0{}.root'.format(i) for i in range(8)]\n",
    "devset_cluster = [root + '/cluster/dlprod_cluster_192px_0{}.root'.format(8)]\n",
    "#testset_cluster = [root + '/cluster/dlprod_cluster_192px_0{}.root'.format(9)]\n",
    "\n",
    "trainset_energy = [root + '/dlprod_192px_0{}.root'.format(i) for i in range(8)]\n",
    "devset_energy = [root + '/dlprod_192px_0{}.root'.format(8)]\n",
    "#testset_energy = [root + '/dlprod_192px_0{}.root'.format(9)]\n",
    "\n",
    "for i, f in enumerate(trainset_cluster):\n",
    "    print(f)\n",
    "    print(trainset_energy[i])\n",
    "    \n",
    "for i, f in enumerate(devset_cluster):\n",
    "    print(f)\n",
    "    print(devset_energy[i])\n",
    "    \n",
    "#for i, f in enumerate(testset_cluster):\n",
    "#    print(f)\n",
    "#    print(testset_energy[i])\n",
    "\n",
    "trainset = ClusteringAEData(root, 192, filenames=[trainset_energy, trainset_cluster])\n",
    "devset = ClusteringAEData(root, 192, filenames=[devset_energy, devset_cluster])\n",
    "#testset = ClusteringAEData(root, 192, filenames=[testset_energy, testset_cluster])\n",
    "print('Number of entries in training set: {}'.format(len(trainset)))\n",
    "print('Number of entries in validation set: {}'.format(len(devset)))\n",
    "#print('Number of entries in test set: {}'.format(len(testset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(trainset, batch_size=1, shuffle=True, collate_fn=ae_collate, num_workers=0, pin_memory=False)\n",
    "devloader = DataLoader(devset, batch_size=1, shuffle=True, collate_fn=ae_collate, num_workers=0, pin_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "entry, labels = trainset[48]\n",
    "coords, energy = entry\n",
    "# coords refer to coordinates of each pixel\n",
    "print(coords)\n",
    "# energy refer to pixel energy values\n",
    "print(energy)\n",
    "# labels refer to cluster labels\n",
    "print(labels)\n",
    "print(\"How many distinct clusters: {}\".format(np.unique(labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from localutil.data import *\n",
    "from localutil.visualization import *\n",
    "from plotly.offline import init_notebook_mode, plot, iplot\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "#import plotly.io as pio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code by Brad Nelson, I redefine the localutil.visualization modules \n",
    "# for better pictures (I set size of markers = 1)\n",
    "\n",
    "def scatter_energy(img_reader, n, threshold=0.0):\n",
    "    \"\"\"\n",
    "    Creates graph object for energy scatter plot\n",
    "    Args:\n",
    "        img_reader (image_reader_3d)\n",
    "        n (int): image to plot\n",
    "        threshold (optional): threshold energies below a certain value\n",
    "    \"\"\"\n",
    "    voxels, energy, labels = img_reader.get_image(n)\n",
    "    inds = energy > threshold\n",
    "    trace = go.Scatter3d(x=voxels[inds,0], y=voxels[inds,1], z=voxels[inds,2],\n",
    "                    mode='markers',\n",
    "                    marker = dict(\n",
    "                        size = 1,\n",
    "                        color = np.log(energy[inds]),\n",
    "                        colorscale='Viridis',\n",
    "                        opacity=0.8\n",
    "                    ), hovertext=energy)\n",
    "    return trace\n",
    "\n",
    "def scatter_classes(img_reader, n):\n",
    "    voxels, types = img_reader.get_image(n)\n",
    "    trace = go.Scatter3d(x=voxels[:,0], y=voxels[:,1], z=voxels[:,2],\n",
    "                    mode='markers',\n",
    "                    marker = dict(\n",
    "                        size = 1,\n",
    "                        color = types,\n",
    "                        colorscale='Viridis',\n",
    "                        opacity=0.8\n",
    "                    ), hovertext=types)\n",
    "    return trace\n",
    "\n",
    "def scatter_clusters(voxels, clusters):\n",
    "    trace = go.Scatter3d(x=voxels[:,0], y=voxels[:,1], z=voxels[:,2],\n",
    "                    mode='markers',\n",
    "                    marker = dict(\n",
    "                        size = 1,\n",
    "                        color = clusters,\n",
    "                        colorscale='Viridis',\n",
    "                        opacity=0.8\n",
    "                    ), hovertext=clusters)\n",
    "    return trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eventn = 48\n",
    "trace1 = scatter_classes(trainset.cluster_reader, eventn)\n",
    "trace2 = scatter_energy(trainset.energy_reader, eventn)\n",
    "fig = go.Figure(data=[trace1])\n",
    "iplot(fig)\n",
    "#pio.write_image(fig, 'images/fig1.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(coords)\n",
    "print(energy)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "labels_plotting = labels.numpy().astype(int)\n",
    "labels_plotting = pd.Series(labels_plotting)\n",
    "labels_plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colorsIdx = {0: 'rgb(31, 119, 180)', 1: 'rgb(255, 127, 14)',\n",
    "             2: 'rgb(44, 160, 44)', 3: 'rgb(214, 39, 40)',\n",
    "             4: 'rgb(148, 103, 189)', 5:'rgb(140, 86, 75)',\n",
    "             6: 'rgb(227, 119, 194)', 7: 'rgb(127, 127, 127)',\n",
    "             8: 'rgb(188, 189, 34)', 9: 'rgb(23, 190, 207)',\n",
    "             17: 'rgb(255,234,0)', 18: 'rgb(255,111,0)',\n",
    "             24: 'rgb(150,0,90)', 42: 'rgb(0,0,200)'}\n",
    "cols      = labels_plotting.map(colorsIdx)\n",
    "\n",
    "trace = go.Scatter3d(x=coords[:,0], y=coords[:,1], z=coords[:,2],\n",
    "                    mode='markers',\n",
    "                    marker = dict(\n",
    "                        size = 1,\n",
    "                        color = cols,\n",
    "                        opacity=0.8\n",
    "                    ), hovertext=labels_plotting)\n",
    "fig = go.Figure(data=[trace])\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, each row of 'coords' is the x,y,z coordinates of the active pixels of the 3D tensor, and each row of 'y' is the value of the pixel at the corresponding 'coords' coordinates. That is, at (97, 42, 5) we have pixel value 0.0156. This notation is called a Sparse Representation since it only gives the active pixel sites for a large sparse matrix. Here, there are only two clusters, since np.unique(labels) gives 0 and 2, which are the integer labels of the clusters. We have one label per pixel site. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: \n",
    "### 1. Make 3D Visualization for Sparse Matrices\n",
    "### 2. Run DBSCAN on each cluster example and see how it performs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Pretrained UResNet Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UResNet(torch.nn.Module):\n",
    "    def __init__(self, dim=3, size=192, nFeatures=16, depth=5, nClasses=5):\n",
    "        import sparseconvnet as scn\n",
    "        super(UResNet, self).__init__()\n",
    "        #self._flags = flags\n",
    "        dimension = dim\n",
    "        reps = 2  # Conv block repetition factor\n",
    "        kernel_size = 2  # Use input_spatial_size method for other values?\n",
    "        m = nFeatures  # Unet number of features\n",
    "        nPlanes = [i*m for i in range(1, depth+1)]  # UNet number of features per level\n",
    "        # nPlanes = [(2**i) * m for i in range(1, num_strides+1)]  # UNet number of features per level\n",
    "        nInputFeatures = 1\n",
    "        self.sparseModel = scn.Sequential().add(\n",
    "           scn.InputLayer(dimension, size, mode=3)).add(\n",
    "           scn.SubmanifoldConvolution(dimension, nInputFeatures, m, 3, False)).add( # Kernel size 3, no bias\n",
    "           scn.UNet(dimension, reps, nPlanes, residual_blocks=True, downsample=[kernel_size, 2])).add(  # downsample = [filter size, filter stride]\n",
    "           scn.BatchNormReLU(m)).add(\n",
    "           scn.OutputLayer(dimension))\n",
    "        self.linear = torch.nn.Linear(m, nClasses)\n",
    "\n",
    "    def forward(self, point_cloud):\n",
    "        \"\"\"\n",
    "        point_cloud is a list of length minibatch size (assumes mbs = 1)\n",
    "        point_cloud[0] has 3 spatial coordinates + 1 batch coordinate + 1 feature\n",
    "        shape of point_cloud[0] = (N, 4)\n",
    "        \"\"\"\n",
    "        #coords = point_cloud[:, 0:-1].float()\n",
    "        #features = point_cloud[:, -1][:, None].float()\n",
    "        x = self.sparseModel(point_cloud)\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unet(fname, dimension=3, size=192, nFeatures=16, depth=5, nClasses=5):\n",
    "    model = UResNet(dim=dimension, size=size, nFeatures=nFeatures, depth=depth, nClasses=nClasses)\n",
    "    model = nn.DataParallel(model)\n",
    "    #print(model.state_dict().keys())\n",
    "    checkpoint = torch.load(fname, map_location='cpu')\n",
    "    #print()\n",
    "    #print(checkpoint['state_dict'].keys())\n",
    "    model.load_state_dict(checkpoint['state_dict'], strict=True)\n",
    "    # just return the pre-trained unet\n",
    "    return model.module.sparseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = '/gpfs/slac/staas/fs1/g/neutrino/.scn_paper/new/sparse_is192_uns5_uf16_bs64/weights3/snapshot-29999.ckpt'\n",
    "#unet = get_unet(fname)\n",
    "unet = UResNet()\n",
    "unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(checkpoint_path, model, optimizer):\n",
    "    # state_dict: a Python dictionary object that:\n",
    "    # - for a model, maps each layer to its parameter tensor;\n",
    "    # - for an optimizer, contains info about the optimizer’s states and hyperparameters used.\n",
    "    state = {\n",
    "        'state_dict': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict()}\n",
    "    torch.save(state, checkpoint_path)\n",
    "    print('model saved to %s' % checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(checkpoint_path, model, optimizer):\n",
    "    state = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(state['state_dict'])\n",
    "    optimizer.load_state_dict(state['optimizer'])\n",
    "    print('model loaded from %s' % checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loss import DiscriminativeLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = DiscriminativeLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = unet.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_epochs=10\n",
    "#training_epoch=scn.checkpoint_restore(unet,exp_name,'unet',use_cuda)\n",
    "optimizer = optim.Adam(unet.parameters())\n",
    "print('#classifer parameters', sum([x.nelement() for x in unet.parameters()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_loss = open('loss.csv', 'w')\n",
    "f_acc = open('acc.csv', 'w')\n",
    "lossWriter = csv.writer(f_loss, delimiter=',')\n",
    "accWriter = csv.writer(f_acc, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "trainset_len = len(trainset)\n",
    "\n",
    "for epoch in range(1, training_epochs+1):\n",
    "    unet.train()\n",
    "    stats = {}\n",
    "    scn.forward_pass_multiplyAdd_count=0\n",
    "    scn.forward_pass_hidden_states=0\n",
    "    start = time.time()\n",
    "    train_loss=0\n",
    "    for i,batch in enumerate(trainloader):\n",
    "        optimizer.zero_grad()\n",
    "        data = batch[0]\n",
    "        label = batch[1][0]\n",
    "        coord, energy = data[0]\n",
    "        if use_cuda:\n",
    "            coord, energy = coord.cuda(), energy.cuda()\n",
    "        try:\n",
    "            out = unet((coord, energy))\n",
    "            out = out.cpu()\n",
    "            loss = criterion(out, label)\n",
    "            train_loss+=loss.item()\n",
    "            loss.backward()\n",
    "            print(\"Examples = {}/{}, Loss = {}\".format(i+1, trainset_len, loss))\n",
    "            optimizer.step()\n",
    "            lossWriter.writerow([loss.item()])\n",
    "        except:\n",
    "            print(\"Warning: Error Encounterd!!\")\n",
    "            continue\n",
    "    print(epoch,'Train loss',train_loss/(i+1), \n",
    "          'MegaMulAdd=',scn.forward_pass_multiplyAdd_count/len(data.train)/1e6, \n",
    "          'MegaHidden',scn.forward_pass_hidden_states/len(data.train)/1e6,\n",
    "          'time=',time.time() - start,'s')\n",
    "#scn.checkpoint_save(unet,exp_name,'unet',epoch, use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_test = scn.InputLayer(3, 192, mode=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainiter = iter(trainloader)\n",
    "batch = trainiter.next()\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_batch = batch[0]\n",
    "y_batch = batch[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet(x_batch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord, energy = x_batch[0]\n",
    "coord = coord.cuda()\n",
    "energy = energy.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = unet((coord, energy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion(out, y_batch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
