{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.14/04\n"
     ]
    }
   ],
   "source": [
    "# Import Dependencies\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "#%matplotlib notebook\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"./dlp_opendata_api\")\n",
    "#sys.path.append(\"../new_notebooks/ipynb\")\n",
    "from osf.image_api import image_reader_3d\n",
    "from osf.particle_api import *\n",
    "from osf.cluster_api import *\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import sparseconvnet as scn\n",
    "import glob\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TESTSET_SIZE = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ls /gpfs/slac/staas/fs1/g/neutrino/kterao/data/dlprod_ppn_v10\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UResNet(torch.nn.Module):\n",
    "    def __init__(self, dim=3, size=192, nFeatures=16, depth=5, nClasses=5):\n",
    "        import sparseconvnet as scn\n",
    "        super(UResNet, self).__init__()\n",
    "        #self._flags = flags\n",
    "        dimension = dim\n",
    "        reps = 2  # Conv block repetition factor\n",
    "        kernel_size = 2  # Use input_spatial_size method for other values?\n",
    "        m = nFeatures  # Unet number of features\n",
    "        nPlanes = [i*m for i in range(1, depth+1)]  # UNet number of features per level\n",
    "        # nPlanes = [(2**i) * m for i in range(1, num_strides+1)]  # UNet number of features per level\n",
    "        nInputFeatures = 1\n",
    "        self.sparseModel = scn.Sequential().add(\n",
    "           scn.InputLayer(dimension, size, mode=3)).add(\n",
    "           scn.SubmanifoldConvolution(dimension, nInputFeatures, m, 3, False)).add( # Kernel size 3, no bias\n",
    "           scn.UNet(dimension, reps, nPlanes, residual_blocks=True, downsample=[kernel_size, 2])).add(  # downsample = [filter size, filter stride]\n",
    "           scn.BatchNormReLU(m)).add(\n",
    "           scn.OutputLayer(dimension))\n",
    "        self.linear = torch.nn.Linear(m, nClasses)\n",
    "\n",
    "    def forward(self, point_cloud):\n",
    "        \"\"\"\n",
    "        point_cloud is a list of length minibatch size (assumes mbs = 1)\n",
    "        point_cloud[0] has 3 spatial coordinates + 1 batch coordinate + 1 feature\n",
    "        shape of point_cloud[0] = (N, 4)\n",
    "        \"\"\"\n",
    "        #coords = point_cloud[:, 0:-1].float()\n",
    "        #features = point_cloud[:, -1][:, None].float()\n",
    "        x = self.sparseModel(point_cloud)\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unet(fname, dimension=3, size=192, nFeatures=16, depth=5, nClasses=5):\n",
    "    model = UResNet(dim=dimension, size=size, nFeatures=nFeatures, depth=depth, nClasses=nClasses)\n",
    "    model = nn.DataParallel(model)\n",
    "    #print(model.state_dict().keys())\n",
    "    checkpoint = torch.load(fname, map_location='cpu')\n",
    "    #print()\n",
    "    #print(checkpoint['state_dict'].keys())\n",
    "    model.load_state_dict(checkpoint['state_dict'], strict=True)\n",
    "    # just return the pre-trained unet\n",
    "    return model.module.sparseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = './unet.ckpt'\n",
    "unet = get_unet(fname)\n",
    "unet = unet.cpu()\n",
    "unet = unet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClusteringAEData(Dataset):\n",
    "    \"\"\"\n",
    "    A customized data loader for clustering.\n",
    "    \"\"\"\n",
    "    def __init__(self, root, numPixels=192, filenames=None):\n",
    "        \"\"\"\n",
    "        Initialize Clustering Dataset\n",
    "\n",
    "        Inputs:\n",
    "            - root: root directory of dataset\n",
    "            - preload: if preload dataset into memory.\n",
    "        \"\"\"\n",
    "        self.cluster_filenames = []\n",
    "        self.energy_filenames = []\n",
    "        self.root = root\n",
    "        self.numPixels = str(numPixels)\n",
    "        \n",
    "        if filenames:\n",
    "            self.energy_filenames = filenames[0]\n",
    "            self.cluster_filenames = filenames[1]\n",
    "            print(self.energy_filenames)\n",
    "\n",
    "        self.energy_filenames.sort()\n",
    "        self.cluster_filenames.sort()\n",
    "        self.cluster_reader = cluster_reader(*self.cluster_filenames)\n",
    "        self.energy_reader = image_reader_3d(*self.energy_filenames)\n",
    "        self.len = self.energy_reader.entry_count()\n",
    "        assert self.len == self.cluster_reader.entry_count()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Get a sample from dataset.\n",
    "        \"\"\"\n",
    "        voxel, label = self.cluster_reader.get_image(index)\n",
    "        _, energy, _ = self.energy_reader.get_image(index)\n",
    "        voxel, label = torch.from_numpy(voxel), torch.from_numpy(label)\n",
    "        energy = torch.from_numpy(energy)\n",
    "        energy = torch.unsqueeze(energy, dim=1)\n",
    "        label = torch.unsqueeze(label, dim=1).type(torch.LongTensor)\n",
    "        voxel = voxel.cpu()\n",
    "        energy = energy.cpu()\n",
    "        with torch.no_grad():\n",
    "            out = unet((voxel, energy))\n",
    "        return out, label\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Total number of sampels in dataset.\n",
    "        \"\"\"\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ae_collate(batch):\n",
    "    \"\"\"\n",
    "    Custom collate_fn for Autoencoder.\n",
    "    \"\"\"\n",
    "    data = [item[0] for item in batch]\n",
    "    target = [item[1] for item in batch]\n",
    "    return [data, target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./dlp_192px_cluster/dlprod_cluster_192px_00.root\n",
      "./dlp_192px_data/dlprod_192px_00.root\n",
      "./dlp_192px_cluster/dlprod_cluster_192px_08.root\n",
      "./dlp_192px_data/dlprod_192px_08.root\n",
      "['./dlp_192px_data/dlprod_192px_00.root']\n",
      "['./dlp_192px_data/dlprod_192px_08.root']\n",
      "Number of entries in training set: 10000\n",
      "Number of entries in validation set: 10000\n"
     ]
    }
   ],
   "source": [
    "root = './' #replace with your own path to root folder. \n",
    "trainset_cluster = [root+'dlp_192px_cluster/dlprod_cluster_192px_00.root']\n",
    "devset_cluster = [root+'dlp_192px_cluster/dlprod_cluster_192px_08.root']\n",
    "#testset_cluster = [root + '/cluster/dlprod_cluster_192px_0{}.root'.format(9)]\n",
    "\n",
    "trainset_energy = [root+'dlp_192px_data/dlprod_192px_00.root']\n",
    "devset_energy = [root+'dlp_192px_data/dlprod_192px_08.root']\n",
    "#testset_energy = [root + '/dlprod_192px_0{}.root'.format(9)]\n",
    "\n",
    "for i, f in enumerate(trainset_cluster):\n",
    "    print(f)\n",
    "    print(trainset_energy[i])\n",
    "    \n",
    "for i, f in enumerate(devset_cluster):\n",
    "    print(f)\n",
    "    print(devset_energy[i])\n",
    "    \n",
    "#for i, f in enumerate(testset_cluster):\n",
    "#    print(f)\n",
    "#    print(testset_energy[i])\n",
    "\n",
    "trainset = ClusteringAEData(root, 192, filenames=[trainset_energy, trainset_cluster])\n",
    "devset = ClusteringAEData(root, 192, filenames=[devset_energy, devset_cluster])\n",
    "#testset = ClusteringAEData(root, 192, filenames=[testset_energy, testset_cluster])\n",
    "print('Number of entries in training set: {}'.format(len(trainset)))\n",
    "print('Number of entries in validation set: {}'.format(len(devset)))\n",
    "#print('Number of entries in test set: {}'.format(len(testset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(trainset, batch_size=1, shuffle=True, collate_fn=ae_collate, num_workers=0, pin_memory=False)\n",
    "#devloader = DataLoader(devset, batch_size=1, shuffle=True, collate_fn=ae_collate, num_workers=0, pin_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "entry, labels = trainset[48]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5180, 16])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entry.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5180, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loss import DiscriminativeLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = DiscriminativeLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.7519)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion(entry, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClusteringMLP(nn.Module):\n",
    "    def __init__(self, input_dim=16, nHidden1=32, nHidden2=16, nClasses=2):\n",
    "        super(ClusteringMLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, nHidden1)\n",
    "        nn.init.kaiming_normal_(self.fc1.weight)\n",
    "        self.fc2 = nn.Linear(nHidden1, nHidden2)\n",
    "        nn.init.kaiming_normal_(self.fc2.weight)\n",
    "        self.fc3 = nn.Linear(nHidden2, nClasses)\n",
    "        nn.init.kaiming_normal_(self.fc3.weight)\n",
    "        \n",
    "        self.bn_1 = nn.BatchNorm1d(nHidden1)\n",
    "        self.bn_2 = nn.BatchNorm1d(nHidden2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.bn_1(self.fc1(x)))\n",
    "        x = F.leaky_relu(self.bn_2(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ClusteringMLP()\n",
    "#model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(entry)\n",
    "loss = criterion(out, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.7566, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainiter = iter(trainloader)\n",
    "x_batch, y_batch = trainiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3838, 16])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_batch[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import MeanShift\n",
    "from sklearn.metrics import adjusted_mutual_info_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(out, labels, model):\n",
    "    out = out.detach().numpy()\n",
    "    model = model.eval()\n",
    "    with torch.no_grad():\n",
    "        model_labels = MeanShift(bandwidth=0.5, bin_seeding=True).fit(out).labels_\n",
    "        score = adjusted_mutual_info_score(labels.squeeze(), model_labels)  \n",
    "        return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "f_train_loss = open('train_loss.csv', 'w')\n",
    "f_train_acc = open('train_acc.csv', 'w')\n",
    "trainlossWriter = csv.writer(f_train_loss, delimiter=',')\n",
    "trainaccWriter = csv.writer(f_train_acc, delimiter=',')\n",
    "\n",
    "f_dev_loss = open('dev_loss.csv', 'w')\n",
    "f_dev_acc = open('dev_acc.csv', 'w')\n",
    "devlossWriter = csv.writer(f_dev_loss, delimiter=',')\n",
    "devaccWriter = csv.writer(f_dev_acc, delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('#classifer parameters', 1202)\n"
     ]
    }
   ],
   "source": [
    "training_epochs=10\n",
    "#training_epoch=scn.checkpoint_restore(unet,exp_name,'unet',use_cuda)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "print('#classifer parameters', sum([x.nelement() for x in model.parameters()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(checkpoint_path, model, optimizer):\n",
    "    # state_dict: a Python dictionary object that:\n",
    "    # - for a model, maps each layer to its parameter tensor;\n",
    "    # - for an optimizer, contains info about the optimizer’s states and hyperparameters used.\n",
    "    state = {\n",
    "        'state_dict': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict()}\n",
    "    torch.save(state, checkpoint_path)\n",
    "    print('model saved to %s' % checkpoint_path)\n",
    "    \n",
    "def load_checkpoint(checkpoint_path, model, optimizer):\n",
    "    state = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(state['state_dict'])\n",
    "    optimizer.load_state_dict(state['optimizer'])\n",
    "    print('model loaded from %s' % checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = torch.utils.data.sampler.RandomSampler(devset, True, TESTSET_SIZE)\n",
    "devloader = DataLoader(devset, sampler=sampler, batch_size=16, collate_fn=ae_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, devloader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    test_accuracy = 0\n",
    "    with torch.no_grad():\n",
    "        for k, batch in enumerate(devloader):\n",
    "            x_batch = batch[0]\n",
    "            y_batch = batch[1]\n",
    "            for j, data in enumerate(x_batch):\n",
    "                try:\n",
    "                    out = model(data)\n",
    "                    loss = criterion(out, y_batch[j])\n",
    "                    acc = accuracy(out, y_batch[j], model)\n",
    "                    test_loss += loss\n",
    "                    test_accuracy += acc\n",
    "                    #print('loss: ', loss.item(), ' acc: ', acc.item())\n",
    "                except:\n",
    "                    print(\"Warning: Error Encounterd!!\")\n",
    "                    continue            \n",
    "                \n",
    "    \n",
    "    return test_loss.item() / float(TESTSET_SIZE), test_accuracy.item()/float(TESTSET_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/cluster/supervised.py:732: FutureWarning: The behavior of AMI will change in version 0.22. To match the behavior of 'v_measure_score', AMI will use average_method='arithmetic' by default.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples = 1/10000, Loss = 2.8373837471, Accuracy = 0.0932963583634\n",
      "('loss: ', 6.047755737304687, ' acc: ', 0.26080959224275074)\n",
      "model saved to checkpoint1.ckpt\n",
      "Examples = 2/10000, Loss = 4.46273851395, Accuracy = -1.44673175611e-15\n",
      "Examples = 3/10000, Loss = 3.39613652229, Accuracy = 0.30541374024\n",
      "Examples = 4/10000, Loss = 5.19240140915, Accuracy = 0.187999725367\n",
      "Examples = 5/10000, Loss = 4.08955430984, Accuracy = 0.0309019264591\n",
      "Examples = 6/10000, Loss = 5.74718475342, Accuracy = 0.0768757221121\n",
      "Examples = 7/10000, Loss = 5.68146657944, Accuracy = 0.118630859432\n",
      "Examples = 8/10000, Loss = 5.04599952698, Accuracy = 0.2506013661\n",
      "Examples = 9/10000, Loss = 3.39339900017, Accuracy = 0.504605019051\n",
      "Examples = 10/10000, Loss = 3.20865893364, Accuracy = 0.316581606188\n",
      "Examples = 11/10000, Loss = 5.50170040131, Accuracy = 0.0579477741015\n",
      "Examples = 12/10000, Loss = 4.90642929077, Accuracy = 0.0901817180181\n",
      "Examples = 13/10000, Loss = 3.15490293503, Accuracy = 0.326199128494\n",
      "Examples = 14/10000, Loss = 5.53780889511, Accuracy = 0.480498784383\n",
      "Examples = 15/10000, Loss = 0.252123773098, Accuracy = 3.12726616793e-17\n",
      "Examples = 16/10000, Loss = 6.34391069412, Accuracy = 0.0131960653232\n",
      "Examples = 17/10000, Loss = 2.9573032856, Accuracy = 0.261728730764\n",
      "Examples = 18/10000, Loss = 4.33415603638, Accuracy = 0.128784675657\n",
      "Examples = 19/10000, Loss = 4.66152048111, Accuracy = 0.170200839224\n",
      "Examples = 20/10000, Loss = 1.44955348969, Accuracy = 0.230718862638\n",
      "Examples = 21/10000, Loss = 4.02825927734, Accuracy = 0.362785920347\n",
      "Examples = 22/10000, Loss = 4.85240793228, Accuracy = 0.214193196288\n",
      "Examples = 23/10000, Loss = 6.08860778809, Accuracy = 0.400124430803\n",
      "Examples = 24/10000, Loss = 6.66644048691, Accuracy = 0.00768137962286\n",
      "Examples = 25/10000, Loss = 4.18266439438, Accuracy = 0.0774399287939\n",
      "Examples = 26/10000, Loss = 2.58010292053, Accuracy = 0.253817998461\n",
      "Examples = 27/10000, Loss = 3.86986517906, Accuracy = 0.364131602027\n",
      "Examples = 28/10000, Loss = 4.02919626236, Accuracy = 0.273194692369\n",
      "Examples = 29/10000, Loss = 2.35513091087, Accuracy = 0.0638011148964\n",
      "Examples = 30/10000, Loss = 2.99498033524, Accuracy = 0.49504254349\n",
      "Examples = 31/10000, Loss = 3.93882632256, Accuracy = 0.25942033858\n",
      "Examples = 32/10000, Loss = 2.63189864159, Accuracy = 0.242654670779\n",
      "Examples = 33/10000, Loss = 5.00484085083, Accuracy = 0.244479408592\n",
      "Examples = 34/10000, Loss = 0.160608753562, Accuracy = -2.71959369735e-16\n",
      "Examples = 35/10000, Loss = 4.14443016052, Accuracy = 0.470600477538\n",
      "Examples = 36/10000, Loss = 3.96780228615, Accuracy = 0.390024494701\n",
      "Examples = 37/10000, Loss = 2.50934028625, Accuracy = 0.12061777176\n",
      "Examples = 38/10000, Loss = 2.97765874863, Accuracy = 0.272674501315\n",
      "Examples = 39/10000, Loss = 3.66735291481, Accuracy = 0.304438605061\n",
      "Examples = 40/10000, Loss = 1.31137728691, Accuracy = 0.288289268604\n",
      "Examples = 41/10000, Loss = 3.37403869629, Accuracy = 0.0827793546541\n",
      "Examples = 42/10000, Loss = 4.21085166931, Accuracy = 0.432189516994\n",
      "Examples = 43/10000, Loss = 3.14361548424, Accuracy = 0.304857439806\n",
      "Examples = 44/10000, Loss = 3.54370307922, Accuracy = 0.368332115048\n",
      "Examples = 45/10000, Loss = 3.47311711311, Accuracy = 0.352614072614\n",
      "Examples = 46/10000, Loss = 2.50167584419, Accuracy = 0.141673439377\n",
      "Examples = 47/10000, Loss = 1.76941680908, Accuracy = 0.269627099591\n",
      "Examples = 48/10000, Loss = 2.85246133804, Accuracy = 0.179000206012\n",
      "Examples = 49/10000, Loss = 3.83171463013, Accuracy = 0.266727447502\n",
      "Examples = 50/10000, Loss = 2.68714785576, Accuracy = 0.303979725924\n",
      "Examples = 51/10000, Loss = 2.30129933357, Accuracy = 0.341788664925\n",
      "Examples = 52/10000, Loss = 3.23652410507, Accuracy = 0.107545925128\n",
      "Examples = 53/10000, Loss = 3.6116297245, Accuracy = 0.136349293687\n",
      "Examples = 54/10000, Loss = 1.81955051422, Accuracy = 0.649968958656\n",
      "Examples = 55/10000, Loss = 4.11532831192, Accuracy = 0.34352259957\n",
      "Examples = 56/10000, Loss = 2.70421600342, Accuracy = 0.344912684521\n",
      "Examples = 57/10000, Loss = 2.44253945351, Accuracy = 0.313808643441\n",
      "Examples = 58/10000, Loss = 1.52384221554, Accuracy = 0.0239152125143\n",
      "Examples = 59/10000, Loss = 5.77928733826, Accuracy = 0.193527682913\n",
      "Examples = 60/10000, Loss = 7.69764947891, Accuracy = 0.0135577072285\n",
      "Examples = 61/10000, Loss = 1.87935340405, Accuracy = 0.319655211155\n",
      "Examples = 62/10000, Loss = 3.8724937439, Accuracy = 0.327782804146\n",
      "Examples = 63/10000, Loss = 3.99837517738, Accuracy = 0.280349711088\n",
      "Examples = 64/10000, Loss = 2.69820451736, Accuracy = 0.504108753833\n",
      "Examples = 65/10000, Loss = 1.92567503452, Accuracy = 0.344399413524\n",
      "Examples = 66/10000, Loss = 0.230958297849, Accuracy = -1.41298040468e-16\n",
      "Examples = 67/10000, Loss = 2.90508627892, Accuracy = 0.346227106278\n",
      "Examples = 68/10000, Loss = 3.3289399147, Accuracy = 0.430817461616\n",
      "Examples = 69/10000, Loss = 1.56770694256, Accuracy = 0.271164206353\n",
      "Examples = 70/10000, Loss = 2.91141176224, Accuracy = 0.452725250746\n",
      "Examples = 71/10000, Loss = 6.06808900833, Accuracy = 0.0184362287913\n",
      "Examples = 72/10000, Loss = 4.87919330597, Accuracy = 0.0457480405375\n",
      "Examples = 73/10000, Loss = 3.26964211464, Accuracy = 0.32498524701\n",
      "Examples = 74/10000, Loss = 2.83959984779, Accuracy = 0.536625645361\n",
      "Examples = 75/10000, Loss = 2.59187412262, Accuracy = 0.0382067095278\n",
      "Examples = 76/10000, Loss = 2.88723039627, Accuracy = 0.274139610596\n",
      "Examples = 77/10000, Loss = 3.03391599655, Accuracy = 0.385267036229\n",
      "Examples = 78/10000, Loss = 2.54159164429, Accuracy = 0.350213142286\n",
      "Examples = 79/10000, Loss = 3.07415866852, Accuracy = 0.0495384554909\n",
      "Examples = 80/10000, Loss = 2.91659164429, Accuracy = 0.418639580708\n",
      "Examples = 81/10000, Loss = 2.64290142059, Accuracy = 0.373112698946\n",
      "Examples = 82/10000, Loss = 2.65346097946, Accuracy = 0.279706576143\n",
      "Examples = 83/10000, Loss = 1.64666724205, Accuracy = 0.675950919145\n",
      "Examples = 84/10000, Loss = 2.48443841934, Accuracy = 0.240267861177\n",
      "Examples = 85/10000, Loss = 0.292330056429, Accuracy = -5.82020668959e-16\n",
      "Examples = 86/10000, Loss = 2.1144361496, Accuracy = 0.412699657305\n",
      "Examples = 87/10000, Loss = 2.40171313286, Accuracy = 0.17244071227\n",
      "Examples = 88/10000, Loss = 0.285565763712, Accuracy = 0.352443516324\n",
      "Examples = 89/10000, Loss = 0.252023726702, Accuracy = 2.03615773687e-15\n",
      "Examples = 90/10000, Loss = 2.68933176994, Accuracy = 0.452270122312\n",
      "Examples = 91/10000, Loss = 3.10914230347, Accuracy = 0.366182934459\n",
      "Examples = 92/10000, Loss = 3.52295851707, Accuracy = 0.2977844272\n",
      "Examples = 93/10000, Loss = 2.06221747398, Accuracy = 0.329220708892\n",
      "Examples = 94/10000, Loss = 2.9325196743, Accuracy = 0.449820341957\n",
      "Examples = 95/10000, Loss = 2.59249186516, Accuracy = 0.234887169021\n",
      "Examples = 96/10000, Loss = 3.24055814743, Accuracy = 0.125969266331\n",
      "Examples = 97/10000, Loss = 2.04291558266, Accuracy = 0.207491798988\n",
      "Examples = 98/10000, Loss = 2.74537467957, Accuracy = 0.304739400431\n",
      "Examples = 99/10000, Loss = 0.385559290648, Accuracy = -6.16266801001e-16\n",
      "Examples = 100/10000, Loss = 1.76470983028, Accuracy = 0.454793901878\n",
      "Examples = 101/10000, Loss = 2.66787719727, Accuracy = 0.312801017007\n",
      "Examples = 102/10000, Loss = 2.39119911194, Accuracy = 0.625496647215\n",
      "Examples = 103/10000, Loss = 2.92903733253, Accuracy = 0.46327613848\n",
      "Examples = 104/10000, Loss = 2.82147049904, Accuracy = 0.400965464008\n",
      "Examples = 105/10000, Loss = 2.61114382744, Accuracy = 0.27493662389\n",
      "Examples = 106/10000, Loss = 2.04229879379, Accuracy = 0.272581355372\n",
      "Examples = 107/10000, Loss = 3.0740506649, Accuracy = 0.294455632737\n",
      "Examples = 108/10000, Loss = 2.05669045448, Accuracy = 0.274730662659\n",
      "Examples = 109/10000, Loss = 1.23754608631, Accuracy = 0.853478187426\n",
      "Examples = 110/10000, Loss = 3.19528675079, Accuracy = 0.416240899002\n",
      "Examples = 111/10000, Loss = 2.3834798336, Accuracy = 0.48237137579\n",
      "Examples = 112/10000, Loss = 2.07314801216, Accuracy = 0.561230520266\n",
      "Examples = 113/10000, Loss = 2.27477645874, Accuracy = 0.354958346403\n",
      "Examples = 114/10000, Loss = 3.12858557701, Accuracy = 0.387644743253\n",
      "Examples = 115/10000, Loss = 2.0506837368, Accuracy = 0.348762847554\n",
      "Examples = 116/10000, Loss = 1.62862014771, Accuracy = 0.457708755827\n",
      "Examples = 117/10000, Loss = 1.8236451149, Accuracy = 0.470608261811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples = 118/10000, Loss = 7.68341398239, Accuracy = 0.00127490335614\n",
      "Examples = 119/10000, Loss = 2.57811379433, Accuracy = 0.121471412271\n",
      "Examples = 120/10000, Loss = 1.56524610519, Accuracy = 0.450207902594\n",
      "Examples = 121/10000, Loss = 2.11308526993, Accuracy = 0.505192482242\n",
      "Examples = 122/10000, Loss = 3.11476135254, Accuracy = 0.280691020058\n",
      "Examples = 123/10000, Loss = 1.77414953709, Accuracy = 0.48860142189\n",
      "Examples = 124/10000, Loss = 4.12544775009, Accuracy = 0.143032534327\n",
      "Examples = 125/10000, Loss = 0.216010123491, Accuracy = 9.01445169789e-17\n",
      "Examples = 126/10000, Loss = 1.22732782364, Accuracy = 0.679071739678\n",
      "Examples = 127/10000, Loss = 1.08383357525, Accuracy = 0.189577036247\n",
      "Examples = 128/10000, Loss = 0.976639389992, Accuracy = 0.635121477883\n",
      "Examples = 129/10000, Loss = 1.22986412048, Accuracy = 0.276225394788\n",
      "Examples = 130/10000, Loss = 1.84712827206, Accuracy = 0.569877724716\n",
      "Examples = 131/10000, Loss = 2.09840679169, Accuracy = 0.449565250443\n",
      "Examples = 132/10000, Loss = 2.05420923233, Accuracy = 0.672602965588\n",
      "Examples = 133/10000, Loss = 2.56292104721, Accuracy = 0.504073345677\n",
      "Examples = 134/10000, Loss = 8.49530410767, Accuracy = 0.0243239902858\n",
      "Examples = 135/10000, Loss = 1.76838731766, Accuracy = 0.487018584654\n",
      "Examples = 136/10000, Loss = 3.19782543182, Accuracy = 0.447763608941\n",
      "Examples = 137/10000, Loss = 1.67715287209, Accuracy = 0.404077695883\n",
      "Examples = 138/10000, Loss = 1.88377189636, Accuracy = 0.35879603392\n",
      "Examples = 139/10000, Loss = 1.36115241051, Accuracy = 0.58249837809\n",
      "Examples = 140/10000, Loss = 2.423630476, Accuracy = 0.495711325619\n",
      "Examples = 141/10000, Loss = 1.93523538113, Accuracy = 0.30370189091\n",
      "Examples = 142/10000, Loss = 0.328723430634, Accuracy = 0.382875329337\n",
      "Examples = 143/10000, Loss = 1.37104988098, Accuracy = 0.186921330954\n",
      "Examples = 144/10000, Loss = 1.74523043633, Accuracy = 0.301738194781\n",
      "Examples = 145/10000, Loss = 0.256980031729, Accuracy = 0.312749834413\n",
      "Examples = 146/10000, Loss = 0.169538289309, Accuracy = 0.327104655976\n",
      "Examples = 147/10000, Loss = 1.82561922073, Accuracy = 0.379471850754\n",
      "Examples = 148/10000, Loss = 0.193006187677, Accuracy = 0.00774127565146\n",
      "Examples = 149/10000, Loss = 2.02513718605, Accuracy = 0.295113591888\n",
      "Examples = 150/10000, Loss = 2.44228291512, Accuracy = 0.691424909783\n",
      "Examples = 151/10000, Loss = 1.90946376324, Accuracy = 0.416804342974\n",
      "Examples = 152/10000, Loss = 1.87347221375, Accuracy = 0.460485065685\n",
      "Examples = 153/10000, Loss = 2.00903391838, Accuracy = 0.275033944612\n",
      "Examples = 154/10000, Loss = 3.8562772274, Accuracy = 0.0668655492221\n",
      "Examples = 155/10000, Loss = 1.45914196968, Accuracy = 0.492852632244\n",
      "Examples = 156/10000, Loss = 1.08526813984, Accuracy = 0.588589799169\n",
      "Examples = 157/10000, Loss = 0.323249131441, Accuracy = 0.615110515888\n",
      "Examples = 158/10000, Loss = 1.69787585735, Accuracy = 0.517125567639\n",
      "Examples = 159/10000, Loss = 0.860084176064, Accuracy = 0.368078060089\n",
      "Examples = 160/10000, Loss = 0.7082067132, Accuracy = 0.413064177458\n",
      "Examples = 161/10000, Loss = 3.35682153702, Accuracy = 0.439168276909\n",
      "Examples = 162/10000, Loss = 1.67569708824, Accuracy = 0.234973003252\n",
      "Examples = 163/10000, Loss = 2.51900410652, Accuracy = 0.416795561136\n",
      "Examples = 164/10000, Loss = 1.4523037672, Accuracy = 0.386166733234\n",
      "Examples = 165/10000, Loss = 1.26494503021, Accuracy = 0.515825024141\n",
      "Examples = 166/10000, Loss = 3.15141320229, Accuracy = 0.154985006595\n",
      "Examples = 167/10000, Loss = 1.39125216007, Accuracy = 0.41378338139\n",
      "Examples = 168/10000, Loss = 1.65082836151, Accuracy = 0.339424429783\n",
      "Examples = 169/10000, Loss = 2.80360531807, Accuracy = 0.452754461146\n",
      "Examples = 170/10000, Loss = 1.79661238194, Accuracy = 0.508785091385\n",
      "Examples = 171/10000, Loss = 2.72611355782, Accuracy = 0.397638147224\n",
      "Examples = 172/10000, Loss = 0.414171874523, Accuracy = 1.49743737009e-15\n",
      "Examples = 173/10000, Loss = 1.72725236416, Accuracy = 0.544728621104\n",
      "Examples = 174/10000, Loss = 0.152467191219, Accuracy = 0.513266980114\n",
      "Examples = 175/10000, Loss = 2.67435407639, Accuracy = 0.58586590917\n",
      "Examples = 176/10000, Loss = 1.29912769794, Accuracy = 0.699715006147\n",
      "Examples = 177/10000, Loss = 0.988768994808, Accuracy = 0.517944364002\n",
      "Examples = 178/10000, Loss = 0.0914164409041, Accuracy = 0.281740527999\n",
      "Examples = 179/10000, Loss = 1.35611248016, Accuracy = 0.527434777011\n",
      "Examples = 180/10000, Loss = 6.595744133, Accuracy = 0.00489622988485\n",
      "Examples = 181/10000, Loss = 2.72385692596, Accuracy = 0.463272345602\n",
      "Examples = 182/10000, Loss = 1.61075174809, Accuracy = 0.515469724383\n",
      "Examples = 183/10000, Loss = 2.5510866642, Accuracy = 0.514115718778\n",
      "Examples = 184/10000, Loss = 0.192349687219, Accuracy = 0.454143435491\n",
      "Examples = 185/10000, Loss = 3.11837506294, Accuracy = 0.215523458255\n",
      "Examples = 186/10000, Loss = 1.8562732935, Accuracy = 0.120292504514\n",
      "Examples = 187/10000, Loss = 1.81060361862, Accuracy = 0.545332907057\n",
      "Examples = 188/10000, Loss = 3.41076993942, Accuracy = 0.304940960135\n",
      "Examples = 189/10000, Loss = 3.10545516014, Accuracy = 0.303424933636\n",
      "Examples = 190/10000, Loss = 2.27651786804, Accuracy = 0.375194631255\n",
      "Examples = 191/10000, Loss = 1.9900084734, Accuracy = 0.324200974748\n",
      "Examples = 192/10000, Loss = 1.82020866871, Accuracy = 0.594286532085\n",
      "Examples = 193/10000, Loss = 4.3303604126, Accuracy = 0.32170414136\n",
      "Examples = 194/10000, Loss = 2.00798606873, Accuracy = 0.212829490623\n",
      "Examples = 195/10000, Loss = 6.40032529831, Accuracy = 0.0348524153717\n",
      "Examples = 196/10000, Loss = 2.13311958313, Accuracy = 0.544535664235\n",
      "Examples = 197/10000, Loss = 1.82703173161, Accuracy = 0.536978733989\n",
      "Examples = 198/10000, Loss = 1.21508419514, Accuracy = 0.537782885044\n",
      "Examples = 199/10000, Loss = 0.678103089333, Accuracy = -4.5598959198e-16\n",
      "Examples = 200/10000, Loss = 6.27144384384, Accuracy = 0.0330452411948\n",
      "Examples = 201/10000, Loss = 0.380942851305, Accuracy = 0.40111309169\n",
      "Examples = 202/10000, Loss = 1.41570651531, Accuracy = 0.533625338193\n",
      "Examples = 203/10000, Loss = 1.01997900009, Accuracy = 0.720285973275\n",
      "Examples = 204/10000, Loss = 1.63855612278, Accuracy = 0.610914698466\n",
      "Examples = 205/10000, Loss = 0.11580966413, Accuracy = 0.114206423316\n",
      "Examples = 206/10000, Loss = 1.49177217484, Accuracy = 0.582679226\n",
      "Examples = 207/10000, Loss = 1.86158382893, Accuracy = 0.43029909416\n",
      "Examples = 208/10000, Loss = 0.539320528507, Accuracy = -7.5558038567e-17\n",
      "Examples = 209/10000, Loss = 1.17576539516, Accuracy = 0.435884471709\n",
      "Examples = 210/10000, Loss = 1.48316884041, Accuracy = 0.373193512258\n",
      "Examples = 211/10000, Loss = 1.58628213406, Accuracy = 0.220262307204\n",
      "Examples = 212/10000, Loss = 1.75818026066, Accuracy = 0.493665937414\n",
      "Examples = 213/10000, Loss = 0.639786660671, Accuracy = 1.09139821633e-15\n",
      "Examples = 214/10000, Loss = 1.2099250555, Accuracy = 0.699641783136\n",
      "Examples = 215/10000, Loss = 0.311912029982, Accuracy = 0.507339112676\n",
      "Examples = 216/10000, Loss = 2.36984395981, Accuracy = 0.640428047256\n",
      "Examples = 217/10000, Loss = 1.68939435482, Accuracy = 0.546827601786\n",
      "Examples = 218/10000, Loss = 1.32339274883, Accuracy = 0.503126089919\n",
      "Examples = 219/10000, Loss = 1.65310645103, Accuracy = 0.652105247429\n",
      "Examples = 220/10000, Loss = 1.16322696209, Accuracy = 0.464160553523\n",
      "Examples = 221/10000, Loss = 2.47113394737, Accuracy = 0.275863440427\n",
      "Examples = 222/10000, Loss = 1.50836825371, Accuracy = 0.16412219269\n",
      "Examples = 223/10000, Loss = 1.66911506653, Accuracy = 0.417106261663\n",
      "Examples = 224/10000, Loss = 2.54753446579, Accuracy = 0.357674979729\n",
      "Examples = 225/10000, Loss = 0.641245901585, Accuracy = 0.170440496844\n",
      "Examples = 226/10000, Loss = 1.65423214436, Accuracy = 0.499362901385\n",
      "Examples = 227/10000, Loss = 7.99392700195, Accuracy = 0.0293688738321\n",
      "Examples = 228/10000, Loss = 1.86936151981, Accuracy = 0.450199820252\n",
      "Examples = 229/10000, Loss = 2.98820734024, Accuracy = 0.310605794717\n",
      "Examples = 230/10000, Loss = 1.45288097858, Accuracy = 0.538699595433\n",
      "Examples = 231/10000, Loss = 1.34812045097, Accuracy = 0.106281503703\n",
      "Examples = 232/10000, Loss = 0.951106071472, Accuracy = 0.573097794876\n",
      "Examples = 233/10000, Loss = 0.654924154282, Accuracy = 0.299014328519\n",
      "Examples = 234/10000, Loss = 1.8053715229, Accuracy = 0.35640664802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples = 235/10000, Loss = 1.37888634205, Accuracy = 0.49881917179\n",
      "Examples = 236/10000, Loss = 0.80257153511, Accuracy = 0.0955639489051\n",
      "Examples = 237/10000, Loss = 0.900274157524, Accuracy = 0.656371775531\n",
      "Examples = 238/10000, Loss = 1.37029731274, Accuracy = 0.458974694576\n",
      "Examples = 239/10000, Loss = 2.30897283554, Accuracy = 0.461597662514\n",
      "Examples = 240/10000, Loss = 0.41233164072, Accuracy = 0.30078274188\n",
      "Examples = 241/10000, Loss = 0.102076537907, Accuracy = 0.385728528059\n",
      "Examples = 242/10000, Loss = 2.87836503983, Accuracy = 0.189242844145\n",
      "Examples = 243/10000, Loss = 1.52727127075, Accuracy = 0.31771441584\n",
      "Examples = 244/10000, Loss = 1.2456766367, Accuracy = 0.645297726289\n",
      "Examples = 245/10000, Loss = 0.968949437141, Accuracy = 0.362732960348\n",
      "Examples = 246/10000, Loss = 0.903204500675, Accuracy = 0.439874179713\n",
      "Examples = 247/10000, Loss = 1.8974916935, Accuracy = 0.299268210788\n",
      "Examples = 248/10000, Loss = 1.49965858459, Accuracy = 0.400631812809\n",
      "Examples = 249/10000, Loss = 1.44717216492, Accuracy = 0.142337774703\n",
      "Examples = 250/10000, Loss = 1.94239997864, Accuracy = 0.578702495365\n",
      "Examples = 251/10000, Loss = 1.41559386253, Accuracy = 0.502275663254\n",
      "Examples = 252/10000, Loss = 0.323863238096, Accuracy = 0.400681188129\n",
      "Examples = 253/10000, Loss = 1.28582310677, Accuracy = 0.438297547072\n",
      "Examples = 254/10000, Loss = 1.39243280888, Accuracy = 0.353862828554\n",
      "Examples = 255/10000, Loss = 0.141801357269, Accuracy = 0.480031830718\n",
      "Examples = 256/10000, Loss = 0.982938051224, Accuracy = 0.444222478279\n",
      "Examples = 257/10000, Loss = 1.78517651558, Accuracy = 0.380088816026\n",
      "Examples = 258/10000, Loss = 1.32533895969, Accuracy = 0.437467188002\n",
      "Examples = 259/10000, Loss = 2.1229569912, Accuracy = 0.375297541757\n",
      "Examples = 260/10000, Loss = 0.455440670252, Accuracy = 0.117541691428\n",
      "Examples = 261/10000, Loss = 1.34345877171, Accuracy = 0.387720082211\n",
      "Examples = 262/10000, Loss = 1.34929144382, Accuracy = 0.377334988628\n",
      "Examples = 263/10000, Loss = 2.01009297371, Accuracy = 0.177761642185\n",
      "Examples = 264/10000, Loss = 1.57953119278, Accuracy = 0.5273704769\n",
      "Examples = 265/10000, Loss = 4.32870817184, Accuracy = 0.122180042341\n",
      "Examples = 266/10000, Loss = 1.19092464447, Accuracy = 0.567784411726\n",
      "Examples = 267/10000, Loss = 0.928325951099, Accuracy = 0.642181224288\n",
      "Examples = 268/10000, Loss = 0.155390173197, Accuracy = 0.432087135118\n",
      "Examples = 269/10000, Loss = 1.39343547821, Accuracy = 0.471416079972\n",
      "Examples = 270/10000, Loss = 1.29549252987, Accuracy = 0.625937321797\n",
      "Examples = 271/10000, Loss = 1.87076807022, Accuracy = 0.50696756434\n",
      "Examples = 272/10000, Loss = 0.948304474354, Accuracy = 0.623150829062\n",
      "Examples = 273/10000, Loss = 0.412416636944, Accuracy = 0.454349978912\n",
      "Examples = 274/10000, Loss = 1.57035410404, Accuracy = 0.442187310233\n",
      "Examples = 275/10000, Loss = 1.75885808468, Accuracy = 0.418381662949\n",
      "Examples = 276/10000, Loss = 0.739909172058, Accuracy = 9.17199241801e-20\n",
      "Examples = 277/10000, Loss = 1.42967534065, Accuracy = 0.502748020456\n",
      "Examples = 278/10000, Loss = 0.32073444128, Accuracy = 0.0663681193542\n",
      "Examples = 279/10000, Loss = 0.958014965057, Accuracy = 0.367225831705\n",
      "Examples = 280/10000, Loss = 0.855388462543, Accuracy = 0.620308790091\n",
      "Examples = 281/10000, Loss = 1.77969372272, Accuracy = 0.451380533828\n",
      "Examples = 282/10000, Loss = 1.46201848984, Accuracy = 0.582093263173\n",
      "Examples = 283/10000, Loss = 1.86928653717, Accuracy = 0.607037513883\n",
      "Examples = 284/10000, Loss = 1.38344061375, Accuracy = 0.451497036403\n",
      "Examples = 285/10000, Loss = 6.89203977585, Accuracy = 0.018186449331\n",
      "Examples = 286/10000, Loss = 1.45442414284, Accuracy = 0.178540178783\n",
      "Examples = 287/10000, Loss = 0.805524528027, Accuracy = 0.566675347054\n",
      "Examples = 288/10000, Loss = 2.97837305069, Accuracy = 0.37432420411\n",
      "Examples = 289/10000, Loss = 1.18077647686, Accuracy = 0.651523789498\n",
      "Examples = 290/10000, Loss = 0.98861515522, Accuracy = 0.45547518836\n",
      "Examples = 291/10000, Loss = 1.47646331787, Accuracy = 0.493222018577\n",
      "Examples = 292/10000, Loss = 0.743596315384, Accuracy = 0.125530456617\n",
      "Examples = 293/10000, Loss = 1.24596238136, Accuracy = 0.631479681899\n",
      "Examples = 294/10000, Loss = 1.30526006222, Accuracy = 0.394279252141\n",
      "Examples = 295/10000, Loss = 2.08319544792, Accuracy = 0.565095021639\n",
      "Examples = 296/10000, Loss = 6.51004838943, Accuracy = 0.0205663642676\n",
      "Examples = 297/10000, Loss = 1.43659591675, Accuracy = 0.455283222194\n",
      "Examples = 298/10000, Loss = 0.255065232515, Accuracy = 0.351968138388\n",
      "Examples = 299/10000, Loss = 2.10959196091, Accuracy = 0.218867865128\n",
      "Examples = 300/10000, Loss = 4.1243057251, Accuracy = 0.378109606548\n",
      "Examples = 301/10000, Loss = 0.21896392107, Accuracy = 0.39203387238\n",
      "Examples = 302/10000, Loss = 2.282299757, Accuracy = 0.209003575335\n",
      "Examples = 303/10000, Loss = 0.253752976656, Accuracy = 0.453236445535\n",
      "Examples = 304/10000, Loss = 1.63102400303, Accuracy = 0.422130110044\n",
      "Examples = 305/10000, Loss = 1.47736144066, Accuracy = 0.289846304636\n",
      "Examples = 306/10000, Loss = 1.56510472298, Accuracy = 0.472469919822\n",
      "Examples = 307/10000, Loss = 0.238914847374, Accuracy = 0.72892017415\n",
      "Examples = 308/10000, Loss = 0.184639677405, Accuracy = 0.319102758927\n",
      "Examples = 309/10000, Loss = 2.83887314796, Accuracy = 0.366688803459\n",
      "Examples = 310/10000, Loss = 0.926739037037, Accuracy = 0.420972852611\n",
      "Examples = 311/10000, Loss = 0.861391484737, Accuracy = 0.355363957004\n",
      "Examples = 312/10000, Loss = 0.449032068253, Accuracy = 0.613674500166\n",
      "Examples = 313/10000, Loss = 1.76745605469, Accuracy = 0.241782492381\n",
      "Examples = 314/10000, Loss = 1.68415367603, Accuracy = 0.413797634786\n",
      "Examples = 315/10000, Loss = 0.644527435303, Accuracy = 0.583167583737\n",
      "Examples = 316/10000, Loss = 3.27751088142, Accuracy = 0.300624106607\n",
      "Examples = 317/10000, Loss = 1.44207262993, Accuracy = 0.57841381016\n",
      "Examples = 318/10000, Loss = 1.01477849483, Accuracy = 0.342316041117\n",
      "Examples = 319/10000, Loss = 2.67990779877, Accuracy = 0.239150211125\n",
      "Examples = 320/10000, Loss = 6.7578868866, Accuracy = 0.0212856543689\n",
      "Examples = 321/10000, Loss = 1.15145599842, Accuracy = 0.540586209782\n",
      "Examples = 322/10000, Loss = 1.23799002171, Accuracy = 0.531431308672\n",
      "Examples = 323/10000, Loss = 1.68627440929, Accuracy = 0.503224535156\n",
      "Examples = 324/10000, Loss = 1.12028861046, Accuracy = 0.484197457645\n",
      "Examples = 325/10000, Loss = 0.763393044472, Accuracy = 0.3035681384\n",
      "Examples = 326/10000, Loss = 0.221209019423, Accuracy = 0.389547811834\n",
      "Examples = 327/10000, Loss = 1.63887584209, Accuracy = 0.527791949677\n",
      "Examples = 328/10000, Loss = 3.49502515793, Accuracy = 0.173698919199\n",
      "Examples = 329/10000, Loss = 1.6523681879, Accuracy = 0.587053358523\n",
      "Examples = 330/10000, Loss = 1.13953471184, Accuracy = 0.41490011541\n",
      "Examples = 331/10000, Loss = 1.17000675201, Accuracy = 0.397064639745\n",
      "Examples = 332/10000, Loss = 2.58323502541, Accuracy = 0.432609439839\n",
      "Examples = 333/10000, Loss = 1.01217520237, Accuracy = 0.559075608441\n",
      "Examples = 334/10000, Loss = 1.34213340282, Accuracy = 0.399179201201\n",
      "Examples = 335/10000, Loss = 0.132832810283, Accuracy = 0.269501308712\n",
      "Examples = 336/10000, Loss = 1.09011256695, Accuracy = 0.43761565181\n",
      "Examples = 337/10000, Loss = 1.46868872643, Accuracy = 0.428527692542\n",
      "Examples = 338/10000, Loss = 0.926917254925, Accuracy = 0.475953925346\n",
      "Examples = 339/10000, Loss = 0.296145945787, Accuracy = 0.497403132258\n",
      "Examples = 340/10000, Loss = 1.29967856407, Accuracy = 0.336766152831\n",
      "Examples = 341/10000, Loss = 2.3996219635, Accuracy = 0.475230413238\n",
      "Examples = 342/10000, Loss = 1.79628717899, Accuracy = 0.439478586217\n",
      "Examples = 343/10000, Loss = 1.09775519371, Accuracy = 0.248160826243\n",
      "Examples = 344/10000, Loss = 0.873480200768, Accuracy = 0.501187476628\n",
      "Examples = 345/10000, Loss = 0.244138225913, Accuracy = 0.363519281134\n",
      "Examples = 346/10000, Loss = 1.40399312973, Accuracy = 0.450621863691\n",
      "Examples = 347/10000, Loss = 1.33196616173, Accuracy = 0.431004864343\n",
      "Examples = 348/10000, Loss = 2.59488272667, Accuracy = 0.24585337532\n",
      "Examples = 349/10000, Loss = 0.545955121517, Accuracy = 0.047888222315\n",
      "Examples = 350/10000, Loss = 0.629176199436, Accuracy = 0.564846503582\n",
      "Examples = 351/10000, Loss = 1.61085402966, Accuracy = 0.572430416249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples = 352/10000, Loss = 1.41038477421, Accuracy = 0.513158514645\n",
      "Examples = 353/10000, Loss = 1.35276222229, Accuracy = 0.666679421763\n",
      "Examples = 354/10000, Loss = 2.38941216469, Accuracy = 0.46131564321\n",
      "Examples = 355/10000, Loss = 1.10178542137, Accuracy = 0.581425937315\n",
      "Examples = 356/10000, Loss = 0.673630356789, Accuracy = 0.430378623388\n",
      "Examples = 357/10000, Loss = 0.14852103591, Accuracy = 0.474749898656\n",
      "Examples = 358/10000, Loss = 1.48384487629, Accuracy = 0.436440578925\n",
      "Examples = 359/10000, Loss = 1.43885612488, Accuracy = 0.410016294134\n",
      "Examples = 360/10000, Loss = 1.43970489502, Accuracy = 0.506756278078\n",
      "Examples = 361/10000, Loss = 0.680622696877, Accuracy = 0.536618845676\n",
      "Examples = 362/10000, Loss = 0.2520378232, Accuracy = 0.175081510568\n",
      "Examples = 363/10000, Loss = 0.059295039624, Accuracy = 0.692820898396\n",
      "Examples = 364/10000, Loss = 1.22262978554, Accuracy = 0.516080169536\n",
      "Examples = 365/10000, Loss = 0.107141010463, Accuracy = 0.312538778273\n",
      "Examples = 366/10000, Loss = 1.04288744926, Accuracy = 0.240371996429\n",
      "Examples = 367/10000, Loss = 1.04506385326, Accuracy = 0.5456418025\n",
      "Examples = 368/10000, Loss = 1.25565183163, Accuracy = 0.223102343456\n",
      "Examples = 369/10000, Loss = 1.68166005611, Accuracy = 0.624602991412\n",
      "Examples = 370/10000, Loss = 7.1570558548, Accuracy = 0.0787273234406\n",
      "Examples = 371/10000, Loss = 1.51619458199, Accuracy = 0.174372215244\n",
      "Examples = 372/10000, Loss = 0.467456489801, Accuracy = 0.419922066968\n",
      "Examples = 373/10000, Loss = 0.277448534966, Accuracy = 0.221549793242\n",
      "Examples = 374/10000, Loss = 6.62495851517, Accuracy = 0.0387381378822\n",
      "Examples = 375/10000, Loss = 1.00835824013, Accuracy = 0.342180653527\n",
      "Examples = 376/10000, Loss = 0.167220070958, Accuracy = 0.257193031671\n",
      "Examples = 377/10000, Loss = 0.975604891777, Accuracy = 0.542798542727\n",
      "Examples = 378/10000, Loss = 0.870022833347, Accuracy = 0.171677016194\n",
      "Examples = 379/10000, Loss = 0.85455083847, Accuracy = 0.622030377682\n",
      "Examples = 380/10000, Loss = 0.609935045242, Accuracy = 0.211784934946\n",
      "Examples = 381/10000, Loss = 1.42850768566, Accuracy = 0.485573346092\n",
      "Examples = 382/10000, Loss = 1.18602144718, Accuracy = 0.415182521977\n",
      "Examples = 383/10000, Loss = 4.30962085724, Accuracy = 0.0575064554499\n",
      "Examples = 384/10000, Loss = 1.69745194912, Accuracy = 0.439872355271\n",
      "Examples = 385/10000, Loss = 1.14461910725, Accuracy = 3.1536787079e-16\n",
      "Examples = 386/10000, Loss = 1.64077341557, Accuracy = 0.583336725081\n",
      "Examples = 387/10000, Loss = 0.931145966053, Accuracy = 0.106194094895\n",
      "Examples = 388/10000, Loss = 1.4525706768, Accuracy = 0.520678021758\n",
      "Examples = 389/10000, Loss = 3.34298825264, Accuracy = 0.54013891487\n",
      "Examples = 390/10000, Loss = 1.9044547081, Accuracy = 0.260057743177\n",
      "Examples = 391/10000, Loss = 0.253328919411, Accuracy = 0.213750531569\n",
      "Examples = 392/10000, Loss = 2.84947013855, Accuracy = 0.346559694868\n",
      "Examples = 393/10000, Loss = 1.21005892754, Accuracy = 0.597322321809\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "errCount = 0\n",
    "trainset_len = len(trainset)\n",
    "\n",
    "for epoch in range(1, training_epochs+1):\n",
    "    stats = {}\n",
    "    start = time.time()\n",
    "    train_loss=0\n",
    "    for i,batch in enumerate(trainloader):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        data = batch[0][0]\n",
    "        label = batch[1][0]\n",
    "        try:\n",
    "            out = model(data)\n",
    "            out = out.cpu()\n",
    "            loss = criterion(out, label)\n",
    "            train_loss+=loss.item()\n",
    "            loss.backward()\n",
    "            acc = accuracy(out, label, model)\n",
    "            print(\"Examples = {}/{}, Loss = {}, Accuracy = {}\".format(i+1, trainset_len, loss, acc))\n",
    "            optimizer.step()\n",
    "            trainlossWriter.writerow([loss.item()])\n",
    "            trainaccWriter.writerow([acc])\n",
    "            if i % 500 == 0:\n",
    "                dev_loss, dev_acc = test(model, devloader)\n",
    "                print('loss: ', dev_loss, ' acc: ', dev_acc)\n",
    "                devlossWriter.writerow([dev_loss])\n",
    "                devaccWriter.writerow([dev_acc])\n",
    "                save_checkpoint('checkpoint{}.ckpt'.format(epoch), model, optimizer)\n",
    "        except:\n",
    "            errCount += 1\n",
    "            print(\"Warning: Error Encounterd!!\")\n",
    "            continue\n",
    "            \n",
    "print(errCount)\n",
    "#scn.checkpoint_save(unet,exp_name,'unet',epoch, use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
