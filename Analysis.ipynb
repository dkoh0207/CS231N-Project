{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparse Submanifold Autoencoders\n",
    "\n",
    "### Run this notebook inside a directory that contains dlp_opendata_api folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.14/04\n"
     ]
    }
   ],
   "source": [
    "# Import Dependencies\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../new_notebooks/ipynb/dlp_opendata_api\")\n",
    "from osf.image_api import image_reader_3d\n",
    "from osf.particle_api import *\n",
    "from osf.cluster_api import *\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import sparseconvnet as scn\n",
    "import glob\n",
    "import os.path as osp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ls /gpfs/slac/staas/fs1/g/neutrino/kterao/data/dlprod_ppn_v10\n",
    "cuda0 = torch.device('cuda:0')\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if CUDA is working (GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClusteringAEData(Dataset):\n",
    "    \"\"\"\n",
    "    A customized data loader for clustering.\n",
    "    \"\"\"\n",
    "    def __init__(self, root, numPixels=192, filenames=None):\n",
    "        \"\"\"\n",
    "        Initialize Clustering Dataset\n",
    "\n",
    "        Inputs:\n",
    "            - root: root directory of dataset\n",
    "            - preload: if preload dataset into memory.\n",
    "        \"\"\"\n",
    "        self.filenames = []\n",
    "        self.root = root\n",
    "        self.numPixels = str(numPixels)\n",
    "        \n",
    "        if filenames:\n",
    "            self.filenames = filenames\n",
    "        else:\n",
    "            self.filenames = [f for f in glob.glob(\n",
    "                osp.join(root, '*.root')) if self.numPixels in f]\n",
    "        self.filenames.sort()\n",
    "        self.ireader = image_reader_3d(*self.filenames)\n",
    "        self.len = self.ireader.entry_count()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Get a sample from dataset.\n",
    "        \"\"\"\n",
    "        voxel, energy, label = self.ireader.get_image(index)\n",
    "        entry = (torch.LongTensor(voxel), torch.FloatTensor(energy).view(-1, 1))\n",
    "        return entry, label\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Total number of sampels in dataset.\n",
    "        \"\"\"\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ae_collate(batch):\n",
    "    \"\"\"\n",
    "    Custom collate_fn for Autoencoder.\n",
    "    \"\"\"\n",
    "    data = [item[0] for item in batch]\n",
    "    target = [item[1] for item in batch]\n",
    "    return [data, target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Train, Dev, and Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/gpfs/slac/staas/fs1/g/neutrino/kterao/data/dlprod_ppn_v10/dlprod_192px_00.root', '/gpfs/slac/staas/fs1/g/neutrino/kterao/data/dlprod_ppn_v10/dlprod_192px_01.root', '/gpfs/slac/staas/fs1/g/neutrino/kterao/data/dlprod_ppn_v10/dlprod_192px_02.root', '/gpfs/slac/staas/fs1/g/neutrino/kterao/data/dlprod_ppn_v10/dlprod_192px_03.root', '/gpfs/slac/staas/fs1/g/neutrino/kterao/data/dlprod_ppn_v10/dlprod_192px_04.root', '/gpfs/slac/staas/fs1/g/neutrino/kterao/data/dlprod_ppn_v10/dlprod_192px_05.root', '/gpfs/slac/staas/fs1/g/neutrino/kterao/data/dlprod_ppn_v10/dlprod_192px_06.root', '/gpfs/slac/staas/fs1/g/neutrino/kterao/data/dlprod_ppn_v10/dlprod_192px_07.root']\n",
      "['/gpfs/slac/staas/fs1/g/neutrino/kterao/data/dlprod_ppn_v10/dlprod_192px_08.root']\n",
      "['/gpfs/slac/staas/fs1/g/neutrino/kterao/data/dlprod_ppn_v10/dlprod_192px_09.root']\n",
      "Number of entries in training set: 80000\n",
      "Number of entries in validation set: 10000\n",
      "Number of entries in test set: 10000\n"
     ]
    }
   ],
   "source": [
    "root = '/gpfs/slac/staas/fs1/g/neutrino/kterao/data/dlprod_ppn_v10' #replace with your own path to root folder. \n",
    "trainset = [root + '/dlprod_192px_0{}.root'.format(i) for i in range(8)]\n",
    "devset = [root + '/dlprod_192px_0{}.root'.format(8)]\n",
    "testset = [root + '/dlprod_192px_0{}.root'.format(9)]\n",
    "print(trainset)\n",
    "print(devset)\n",
    "print(testset)\n",
    "trainset = ClusteringAEData(root, 192, filenames=trainset)\n",
    "devset = ClusteringAEData(root, 192, filenames=devset)\n",
    "testset = ClusteringAEData(root, 192, filenames=testset)\n",
    "print('Number of entries in training set: {}'.format(len(trainset)))\n",
    "print('Number of entries in validation set: {}'.format(len(devset)))\n",
    "print('Number of entries in test set: {}'.format(len(testset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(trainset, batch_size=32, shuffle=True, collate_fn=ae_collate, num_workers=1, pin_memory=False)\n",
    "devloader = DataLoader(devset, batch_size=64, shuffle=True, collate_fn=ae_collate, num_workers=1, pin_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape = torch.Size([3827, 3])\n",
      "y.shape = torch.Size([3827, 1])\n",
      "labels.shape = (3827,)\n",
      "[0. 2.]\n"
     ]
    }
   ],
   "source": [
    "x, y = trainset[0][0]\n",
    "print(\"X.shape = {}\".format(x.shape))\n",
    "print(\"y.shape = {}\".format(y.shape))\n",
    "labels = trainset[0][1]\n",
    "print(\"labels.shape = {}\".format(labels.shape))\n",
    "print(np.unique(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, each row of 'coords' is the x,y,z coordinates of the active pixels of the 3D tensor, and each row of 'y' is the value of the pixel at the corresponding 'coords' coordinates. That is, at (97, 42, 5) we have pixel value 0.0156. This notation is called a Sparse Representation since it only gives the active pixel sites for a large sparse matrix. Here, there are only two clusters, since np.unique(labels) gives 0 and 2, which are the integer labels of the clusters. We have one label per pixel site. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: \n",
    "### 1. Make 3D Visualization for Sparse Matrices\n",
    "### 2. Run DBSCAN on each cluster example and see how it performs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Architectures for Autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseUResNet(torch.nn.Module):\n",
    "    def __init__(self, dimension=3, size=192, nFeatures=16, depth=5, nClasses=1):\n",
    "        super(SparseUResNet, self).__init__()\n",
    "        self.dimension = dimension\n",
    "        self.size = size\n",
    "        self.nFeatures = nFeatures\n",
    "        self.depth = depth\n",
    "        self.nClasses = nClasses\n",
    "        reps = 2  # Conv block repetition factor\n",
    "        kernel_size = 2  # Use input_spatial_size method for other values?\n",
    "        m = nFeatures  # Unet number of features\n",
    "        nPlanes = [i*m for i in range(1, depth+1)]  # UNet number of features per level\n",
    "        nInputFeatures = 1\n",
    "        # From Submanifold Sparse Convnet Github Repo by Benjamin Graham.\n",
    "        self.sparseModel = scn.Sequential().add(\n",
    "           scn.InputLayer(dimension, size, mode=3)).add(\n",
    "           scn.SubmanifoldConvolution(dimension, nInputFeatures, m, 3, False)).add( # Kernel size 3, no bias\n",
    "           scn.UNet(dimension, reps, nPlanes, residual_blocks=True, downsample=[kernel_size, 2])).add(  # downsample = [filter size, filter stride]\n",
    "           scn.BatchNormReLU(m)).add(\n",
    "           scn.OutputLayer(dimension))\n",
    "        self.linear = torch.nn.Linear(m, nClasses)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x is scn coordinate, feature input\n",
    "        \"\"\"\n",
    "        x = self.sparseModel(x)\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LArCVEncoder(nn.Module):\n",
    "    def __init__(self, dim=3, size=192, nFeatures=16):\n",
    "        super(LArCVEncoder, self).__init__()\n",
    "\n",
    "        nIn = nFeatures\n",
    "        nOut = nIn * 2\n",
    "        \n",
    "        self.model = scn.Sequential()\n",
    "        self.model.add(scn.InputLayer(dim, size, mode=3))\n",
    "        self.model.add(scn.SubmanifoldConvolution(dim, 1, nIn, 3, False))\n",
    "        self.model.add(scn.BatchNormLeakyReLU(nIn))\n",
    "        self.model.add(scn.Convolution(dim, nIn, nIn, 2, 2, False))\n",
    "        for _ in range(5):\n",
    "            self.model.add(scn.SubmanifoldConvolution(dim, nIn, nOut, 3, False))\n",
    "            self.model.add(scn.BatchNormLeakyReLU(nOut))\n",
    "            self.model.add(scn.Convolution(dim, nOut, nOut, 2, 2, False))\n",
    "            nIn = nOut\n",
    "            nOut = nIn * 2\n",
    "        self.model.add(scn.AveragePooling(dim, 3, 1))\n",
    "        self.model.add(scn.SparseToDense(3, nIn))\n",
    "        \n",
    "        # Include Linear?\n",
    "        self.fc = nn.Linear(512, 256)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x is scn coordinate, feature input\n",
    "        \"\"\"\n",
    "        x = self.model(x)\n",
    "        print(x.shape)\n",
    "        x = x.view(-1, 512)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LArCVDecoder(nn.Module):\n",
    "    def __init__(self, dim=3, size=192, nFeatures=16, latent_dim=512):\n",
    "        super(LArCVDecoder, self).__init__()\n",
    "\n",
    "        nIn = latent_dim\n",
    "        nOut = nIn // 2\n",
    "        '''\n",
    "        self.model = scn.Sequential()\n",
    "        self.model.add(scn.DenseToSparse(dim))\n",
    "        self.model.add(scn.UnPooling(dim, 3, 1))\n",
    "        for _ in range(5):\n",
    "            self.model.add(\n",
    "                scn.Deconvolution(dim, nIn, nIn, 2, 1, False)).add(\n",
    "                scn.BatchNormLeakyReLU(nIn)).add(\n",
    "                scn.SubmanifoldConvolution(dim, nIn, nOut, 3, False))\n",
    "            nIn = nOut\n",
    "            nOut = nIn // 2\n",
    "        self.model.add(\n",
    "            scn.Deconvolution(dim, nIn, nIn, 2, 1, False)).add(\n",
    "            scn.BatchNormLeakyReLU(nIn)).add(\n",
    "            scn.SubmanifoldConvolution(dim, nIn, nOut, 3, False))\n",
    "        self.model.add(scn.OutputLayer(dim))\n",
    "        '''\n",
    "\n",
    "        self.fc = nn.Linear(256, 512)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x is scn coordinate, feature input\n",
    "        \"\"\"\n",
    "        x = self.fc(x)\n",
    "        x = x.view(-1, 512, 1, 1, 1)\n",
    "        x = scn.DenseToSparse(3)(x)\n",
    "        print(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "InputLayer_updateOutput(): incompatible function arguments. The following argument types are supported:\n    1. (arg0: sparseconvnet.SCN.Metadata_1, arg1: at::Tensor, arg2: at::Tensor, arg3: at::Tensor, arg4: at::Tensor, arg5: int, arg6: int) -> None\n    2. (arg0: sparseconvnet.SCN.Metadata_2, arg1: at::Tensor, arg2: at::Tensor, arg3: at::Tensor, arg4: at::Tensor, arg5: int, arg6: int) -> None\n    3. (arg0: sparseconvnet.SCN.Metadata_3, arg1: at::Tensor, arg2: at::Tensor, arg3: at::Tensor, arg4: at::Tensor, arg5: int, arg6: int) -> None\n    4. (arg0: sparseconvnet.SCN.Metadata_4, arg1: at::Tensor, arg2: at::Tensor, arg3: at::Tensor, arg4: at::Tensor, arg5: int, arg6: int) -> None\n    5. (arg0: sparseconvnet.SCN.Metadata_5, arg1: at::Tensor, arg2: at::Tensor, arg3: at::Tensor, arg4: at::Tensor, arg5: int, arg6: int) -> None\n    6. (arg0: sparseconvnet.SCN.Metadata_6, arg1: at::Tensor, arg2: at::Tensor, arg3: at::Tensor, arg4: at::Tensor, arg5: int, arg6: int) -> None\n\nInvoked with: <sparseconvnet.SCN.Metadata_3 object at 0x7f231856fd18>, tensor([192, 192, 192]), DenseToSparse(3), tensor([[0.0156],\n        [0.0139],\n        [0.0264],\n        ...,\n        [0.0386],\n        [0.0676],\n        [0.0144]]), tensor([]), 0, 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-6e19e205bf55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLArCVEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-600c701e3b84>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mscn\u001b[0m \u001b[0mcoordinate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \"\"\"\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/nn/modules/container.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sparseconvnet/ioLayers.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;36m0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         )\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sparseconvnet/ioLayers.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, dimension, metadata, spatial_size, coords, input_features, batch_size, mode)\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0moutput_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m             \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         )\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: InputLayer_updateOutput(): incompatible function arguments. The following argument types are supported:\n    1. (arg0: sparseconvnet.SCN.Metadata_1, arg1: at::Tensor, arg2: at::Tensor, arg3: at::Tensor, arg4: at::Tensor, arg5: int, arg6: int) -> None\n    2. (arg0: sparseconvnet.SCN.Metadata_2, arg1: at::Tensor, arg2: at::Tensor, arg3: at::Tensor, arg4: at::Tensor, arg5: int, arg6: int) -> None\n    3. (arg0: sparseconvnet.SCN.Metadata_3, arg1: at::Tensor, arg2: at::Tensor, arg3: at::Tensor, arg4: at::Tensor, arg5: int, arg6: int) -> None\n    4. (arg0: sparseconvnet.SCN.Metadata_4, arg1: at::Tensor, arg2: at::Tensor, arg3: at::Tensor, arg4: at::Tensor, arg5: int, arg6: int) -> None\n    5. (arg0: sparseconvnet.SCN.Metadata_5, arg1: at::Tensor, arg2: at::Tensor, arg3: at::Tensor, arg4: at::Tensor, arg5: int, arg6: int) -> None\n    6. (arg0: sparseconvnet.SCN.Metadata_6, arg1: at::Tensor, arg2: at::Tensor, arg3: at::Tensor, arg4: at::Tensor, arg5: int, arg6: int) -> None\n\nInvoked with: <sparseconvnet.SCN.Metadata_3 object at 0x7f231856fd18>, tensor([192, 192, 192]), DenseToSparse(3), tensor([[0.0156],\n        [0.0139],\n        [0.0264],\n        ...,\n        [0.0386],\n        [0.0676],\n        [0.0144]]), tensor([]), 0, 3"
     ]
    }
   ],
   "source": [
    "model = LArCVEncoder()\n",
    "data = (x,y)\n",
    "encoding = model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LArCVDecoder(\n",
       "  (fc): Linear(in_features=256, out_features=512, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LArCVDecoder()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseConvNetTensor<<features=tensor([[-0.2341,  0.1516,  0.3713, -0.3174,  0.2750,  0.4985, -0.0422, -0.2174,\n",
      "         -0.3240,  0.1597,  0.3151, -0.3994, -0.0652, -0.1289,  0.2008, -0.5346,\n",
      "         -0.4977,  0.1207,  0.5712,  0.3493,  0.2991, -0.3894, -0.2912,  0.4324,\n",
      "         -0.1191, -0.0536, -0.3242, -0.2812, -0.0029,  0.0993,  0.0299,  0.1747,\n",
      "         -0.0257, -0.2212,  0.4564,  0.7604, -0.0345,  0.0852, -0.3388, -0.3885,\n",
      "          0.0163, -0.0928,  0.3717,  0.1798, -0.1886,  0.3596,  0.1643, -0.0738,\n",
      "          0.3383, -0.4625,  0.3101,  0.2886, -0.3593,  0.0771,  0.6491,  0.1250,\n",
      "          0.2924,  0.2258,  0.2517,  0.2401,  0.0551,  0.0769, -0.6941,  0.2417,\n",
      "         -0.2873,  0.2176, -0.4363, -0.0334, -0.1325, -0.3338, -0.3243, -0.1483,\n",
      "         -0.5070,  0.8272, -0.7039,  0.2709, -0.0474, -0.2353,  0.2400, -0.2581,\n",
      "          0.5687,  0.1367,  0.0577, -0.6273,  0.2198,  0.1212,  0.2244,  0.1873,\n",
      "         -0.4122, -0.3729,  0.6652,  0.1721, -0.0966,  0.0583,  0.5820, -0.1625,\n",
      "          0.1982, -0.0767,  0.1437,  0.5141, -0.0975,  0.1296,  0.3001, -0.0735,\n",
      "          0.3371, -0.1508,  0.0270,  0.0013,  0.1929, -0.1238, -0.6344,  0.1577,\n",
      "         -0.3176, -0.0010, -0.2433,  0.3867, -0.2258, -0.1765,  0.2905, -0.0942,\n",
      "         -0.1529, -0.2002, -0.2344, -0.4941,  0.1225,  0.8081, -0.0946,  0.5371,\n",
      "         -0.3132,  0.3480,  0.1733, -0.2262, -0.3107,  0.2501, -0.3509, -0.1618,\n",
      "         -0.5882,  0.4276, -0.5664, -0.1404,  0.0757,  0.1033,  0.0758,  0.5829,\n",
      "          0.0532,  0.1434, -0.0975,  0.2335, -0.4985,  0.0496, -0.2021,  0.1352,\n",
      "         -0.4065, -0.1446, -0.0538,  0.1537,  0.1287,  0.0237,  0.1458,  0.0316,\n",
      "          0.0200, -0.3173,  0.0116, -0.1738, -0.2165, -0.1873,  0.1123,  0.1251,\n",
      "         -0.1601, -0.4781,  0.1233, -0.2596,  0.1275,  0.6995, -0.4022,  0.4859,\n",
      "          0.3868,  0.5789, -0.1392,  0.1311,  0.3023, -0.0270, -0.3857,  0.0292,\n",
      "          0.7126,  0.2812, -0.0785, -0.1082, -0.1992,  0.7254,  0.2923, -0.0606,\n",
      "          0.1339,  0.1079,  0.1093,  0.0332, -0.5157,  0.3315,  0.3241,  0.1369,\n",
      "          0.2604,  0.9402,  0.1280,  0.8747, -0.0209,  0.1855, -0.0725, -0.0648,\n",
      "         -0.2144, -0.2662, -0.0709,  0.0537,  0.0346, -0.5682,  0.2999, -0.1844,\n",
      "          0.1203, -0.3223,  0.0838,  0.1456, -0.5960,  0.8253, -0.3866,  0.3670,\n",
      "          0.0613, -0.0894,  0.5389, -0.4597, -0.2688,  0.0609,  0.1622, -0.1396,\n",
      "         -0.0583,  0.1629,  0.4874,  0.6218,  0.0321,  0.6999,  0.5167,  0.6502,\n",
      "          0.2317, -0.2069, -0.4999,  0.1638,  0.2360, -0.5849, -0.1595, -0.0266,\n",
      "          0.1700,  0.8512, -0.1637,  0.5244,  0.2609,  1.0347, -0.2631,  0.4273,\n",
      "         -0.3706, -0.2491,  0.0119,  0.3265, -0.3440, -0.0320, -0.3010,  0.2272,\n",
      "         -0.3370, -0.1626,  0.5148,  0.1736, -0.4104, -0.2117,  0.5853, -0.2697,\n",
      "         -0.2702, -0.3471, -0.0649,  0.0661, -0.3326, -0.2828,  0.1807, -0.0516,\n",
      "         -0.1671,  0.0565, -0.5268, -0.1205,  0.2419,  0.7365, -0.3252, -0.4319,\n",
      "          0.2511, -0.2093, -0.3640, -0.5244, -0.1431, -0.2662, -0.1110, -0.3289,\n",
      "         -0.1500,  0.4048, -0.7201,  0.1361,  0.1488, -0.5178, -0.3132, -0.2194,\n",
      "         -0.3553,  0.2094,  0.1998,  0.1395,  0.1070,  0.0893,  0.1797,  0.1355,\n",
      "          0.0147, -0.0092, -0.3799,  0.0327, -0.2005, -0.1454,  0.0518,  0.2455,\n",
      "          0.0917,  0.6421,  0.3151,  0.4059,  0.2692, -0.1617,  0.1781,  0.3817,\n",
      "         -0.0227,  0.1928,  0.2902, -0.5292, -0.1037,  0.5674, -0.3787, -0.1346,\n",
      "         -0.3750, -0.4398,  0.2070, -0.4630, -0.0534,  0.0953,  0.1004,  0.1846,\n",
      "          0.8102, -0.3125, -0.3625, -0.1149, -0.5782, -0.0929, -0.5220,  0.4221,\n",
      "          0.3637, -0.2418, -0.3930, -0.3781,  0.5498, -0.2257,  0.4341, -0.4317,\n",
      "         -0.1204, -0.2890,  0.7361, -0.4346,  0.1006, -0.9317, -0.7510,  0.0792,\n",
      "          0.2080, -0.7739,  0.3643, -0.1455, -0.2804, -0.3633, -0.0094,  0.5654,\n",
      "         -0.0375, -0.2719,  0.4023,  0.0734, -0.1065,  0.2210,  0.2822,  0.0951,\n",
      "          0.7156, -0.5984, -0.3260, -0.0454, -0.3625, -0.3865, -0.3186, -0.0306,\n",
      "         -0.5870, -0.2318,  0.6008, -0.1515,  0.1566,  0.1733,  0.7205, -0.0320,\n",
      "         -0.1965, -0.0246,  0.1420,  0.0610, -0.0981,  0.2672, -0.0504, -0.2811,\n",
      "          0.5707,  0.6863, -0.1668, -0.3686, -0.3480,  0.0538, -0.0830, -0.3355,\n",
      "         -0.0506,  0.1725, -0.1747, -0.4054,  0.4533,  0.2744, -0.0375, -0.6366,\n",
      "          0.1593,  0.0995, -0.0699, -0.1725, -0.3929,  0.0095, -0.0819, -0.2168,\n",
      "         -0.1712, -0.5007, -0.1251, -0.4439,  0.2061,  0.0836, -0.2420,  0.5534,\n",
      "         -0.0088, -0.7471, -0.5886, -0.2540, -0.4386, -0.3327, -0.0236,  0.0053,\n",
      "         -0.2040, -0.0531,  0.0431,  0.2141, -0.3067, -0.0397, -0.0012, -0.3798,\n",
      "         -0.0705,  0.5523,  0.7424, -0.0564,  0.1144,  0.1059,  0.3775,  0.1552,\n",
      "         -0.1095,  0.3138, -0.1492, -0.1915, -0.1808,  0.4103, -0.1901,  0.0562,\n",
      "         -0.4396, -0.3449, -0.3192,  0.1097, -0.0751,  0.1084, -0.1912, -0.2930,\n",
      "          0.6230, -0.6898,  0.3263,  0.3699, -0.4294,  0.4832,  0.1587, -0.1018,\n",
      "          0.2431, -0.5964,  0.0578, -0.2387, -0.0666, -0.5002,  0.4512, -0.4480,\n",
      "         -0.2202, -0.1062, -0.1720, -0.2566, -0.1258, -0.1083, -0.3064,  0.2189,\n",
      "         -0.0601,  0.1730,  0.2146, -0.4434,  0.2001, -0.0283,  0.0641,  0.3180]],\n",
      "       grad_fn=<DenseToSparseFunctionBackward>),features.shape=torch.Size([1, 512]),batch_locations=tensor([[0, 0, 0, 0]]),batch_locations.shape=torch.Size([1, 4]),spatial size=tensor([1, 1, 1])>>\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(256)\n",
    "x = x.view(-1, 256)\n",
    "x.shape\n",
    "x = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LArCVDecoder(nn.Module):\n",
    "    def __init__(self, dim=3, size=192, nFeatures=16):\n",
    "        super(LArCVEncoder, self).__init__()\n",
    "\n",
    "        nIn = nFeatures\n",
    "        nOut = nIn * 2\n",
    "        \n",
    "        self.fc = nn.Linear(256, 512)\n",
    "        self.model = scn.Sequential()\n",
    "        self.model.add()\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x is scn coordinate, feature input\n",
    "        \"\"\"\n",
    "        x = self.model(x)\n",
    "        x = x.view(-1, 512)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, optimizer, epochs, loss_fn=nn.MSELoss(), use_cuda=False, log=2):\n",
    "    \"\"\"\n",
    "    Function for training SparseUResNet.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    iteration = 0\n",
    "    for ep in range(epochs):\n",
    "        minibatch = torch.zeros\n",
    "        for batch_idx, entry in enumerate(loader):\n",
    "            data, label = entry\n",
    "            optimizer.zero_grad()\n",
    "            batch_ids = [torch.ones((t[0].shape[0], 1),\n",
    "                dtype=torch.long) * batch_idx for t in data]\n",
    "            coords = [torch.cat([t[0], batch_ids[i]], dim=1) \n",
    "                for i, t in enumerate(data)]\n",
    "            coords = torch.cat(coords, dim=0)\n",
    "            energy = [t[1] for t in data]\n",
    "            values = torch.cat(energy, dim=0)\n",
    "            if use_cuda:\n",
    "                coords, values = coords.cuda(), values.cuda()\n",
    "            out = model((coords, values))\n",
    "            loss = loss_fn.forward(out, values)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if iteration % log == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    ep, batch_idx * len(label), len(loader.dataset),\n",
    "                    100. * batch_idx / len(loader), loss.item()))\n",
    "            iteration += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = {}\n",
    "p['n_epochs'] = 100\n",
    "p['initial_lr'] = 1e-1\n",
    "p['lr_decay'] = 4e-2\n",
    "p['weight_decay'] = 1e-4\n",
    "p['momentum'] = 0.9\n",
    "p['check_point'] = False\n",
    "p['use_cuda'] = torch.cuda.is_available()\n",
    "\n",
    "model = SparseUResNet()\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "if p['use_cuda']:\n",
    "    model.cuda()\n",
    "    criterion.cuda()\n",
    "optimizer = optim.SGD(model.parameters(),\n",
    "    lr=p['initial_lr'],\n",
    "    momentum=p['momentum'],\n",
    "    weight_decay=p['weight_decay'],\n",
    "    nesterov=True)\n",
    "\n",
    "train(model, trainloader, optimizer, 1, loss_fn=criterion, use_cuda=use_cuda, log=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxels, energy, labels = ireader.get_image(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.ones(t[0].shape[0], 1, dtype=torch.long) * 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images\n",
    "coords = [torch.cat([t[0], torch.ones(t[0].shape[0], 1, dtype=torch.long) * i], dim=1) for i, t in enumerate(images)]\n",
    "coords = torch.cat(coords, dim=0)\n",
    "print(coords, coords.shape)\n",
    "values = torch.cat([t[1] for t in images], dim=0)\n",
    "print(values, values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords, values = coords.cuda(), values.cuda()\n",
    "data = (coords, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = out - data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "criterion.forward(out, data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_id = torch.ones((voxels.shape[0], 1), dtype=torch.long) * 1\n",
    "print(batch_id)\n",
    "data = coords\n",
    "x = (data, y)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SparseUResNet(3, 192, 16, 5)\n",
    "root = '/gpfs/slac/staas/fs1/g/neutrino/kterao/data/dlprod_ppn_v10'\n",
    "dataset = ClusteringAEData(root, 192)\n",
    "loader = DataLoader(dataset, batch_size=64, shuffle=True, \n",
    "                    collate_fn=ae_collate, num_workers=1)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "p = {}\n",
    "p['n_epochs'] = 100\n",
    "p['initial_lr'] = 1e-1\n",
    "p['lr_decay'] = 4e-2\n",
    "p['weight_decay'] = 1e-4\n",
    "p['momentum'] = 0.9\n",
    "p['check_point'] = False\n",
    "p['use_cuda'] = torch.cuda.is_available()\n",
    "\n",
    "if p['use_cuda']:\n",
    "    model.cuda()\n",
    "    criterion.cuda()\n",
    "optimizer = optim.SGD(model.parameters(),\n",
    "    lr=p['initial_lr'],\n",
    "    momentum=p['momentum'],\n",
    "    weight_decay=p['weight_decay'],\n",
    "    nesterov=True)\n",
    "\n",
    "dtype = 'torch.cuda.FloatTensor' if p['use_cuda'] else 'torch.FloatTensor'\n",
    "dtypei = 'torch.cuda.LongTensor' if p['use_cuda'] else 'torch.LongTensor'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
