{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparse Submanifold Autoencoders\n",
    "\n",
    "### Run this notebook inside a directory that contains dlp_opendata_api folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.14/04\n"
     ]
    }
   ],
   "source": [
    "# Import Dependencies\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"dlp_opendata_api\")\n",
    "from osf.image_api import image_reader_3d\n",
    "from osf.particle_api import *\n",
    "from osf.cluster_api import *\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import sparseconvnet as scn\n",
    "import glob\n",
    "import os.path as osp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ls /gpfs/slac/staas/fs1/g/neutrino/kterao/data/dlprod_ppn_v10\n",
    "cuda0 = torch.device('cuda:0')\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if CUDA is working (GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClusteringAEData(Dataset):\n",
    "    \"\"\"\n",
    "    A customized data loader for clustering.\n",
    "    \"\"\"\n",
    "    def __init__(self, root, numPixels=192, filenames=None):\n",
    "        \"\"\"\n",
    "        Initialize Clustering Dataset\n",
    "\n",
    "        Inputs:\n",
    "            - root: root directory of dataset\n",
    "            - preload: if preload dataset into memory.\n",
    "        \"\"\"\n",
    "        self.filenames = []\n",
    "        self.root = root\n",
    "        self.numPixels = str(numPixels)\n",
    "        \n",
    "        if filenames:\n",
    "            self.filenames = filenames\n",
    "        else:\n",
    "            self.filenames = [f for f in glob.glob(\n",
    "                osp.join(root, '*.root')) if self.numPixels in f]\n",
    "        self.filenames.sort()\n",
    "        self.ireader = image_reader_3d(*self.filenames)\n",
    "        self.len = self.ireader.entry_count()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Get a sample from dataset.\n",
    "        \"\"\"\n",
    "        voxel, energy, label = self.ireader.get_image(index)\n",
    "        entry = (torch.LongTensor(voxel), torch.FloatTensor(energy).view(-1, 1))\n",
    "        return entry, label\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Total number of sampels in dataset.\n",
    "        \"\"\"\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ae_collate(batch):\n",
    "    \"\"\"\n",
    "    Custom collate_fn for Autoencoder.\n",
    "    \"\"\"\n",
    "    data = [item[0] for item in batch]\n",
    "    target = [item[1] for item in batch]\n",
    "    return [data, target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Train, Dev, and Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/gpfs/slac/staas/fs1/g/neutrino/kterao/data/dlprod_ppn_v10/dlprod_192px_00.root', '/gpfs/slac/staas/fs1/g/neutrino/kterao/data/dlprod_ppn_v10/dlprod_192px_01.root', '/gpfs/slac/staas/fs1/g/neutrino/kterao/data/dlprod_ppn_v10/dlprod_192px_02.root', '/gpfs/slac/staas/fs1/g/neutrino/kterao/data/dlprod_ppn_v10/dlprod_192px_03.root', '/gpfs/slac/staas/fs1/g/neutrino/kterao/data/dlprod_ppn_v10/dlprod_192px_04.root', '/gpfs/slac/staas/fs1/g/neutrino/kterao/data/dlprod_ppn_v10/dlprod_192px_05.root', '/gpfs/slac/staas/fs1/g/neutrino/kterao/data/dlprod_ppn_v10/dlprod_192px_06.root', '/gpfs/slac/staas/fs1/g/neutrino/kterao/data/dlprod_ppn_v10/dlprod_192px_07.root']\n",
      "['/gpfs/slac/staas/fs1/g/neutrino/kterao/data/dlprod_ppn_v10/dlprod_192px_08.root']\n",
      "['/gpfs/slac/staas/fs1/g/neutrino/kterao/data/dlprod_ppn_v10/dlprod_192px_09.root']\n",
      "Number of entries in training set: 80000\n",
      "Number of entries in validation set: 10000\n",
      "Number of entries in test set: 10000\n"
     ]
    }
   ],
   "source": [
    "root = '/gpfs/slac/staas/fs1/g/neutrino/kterao/data/dlprod_ppn_v10' #replace with your own path to root folder. \n",
    "trainset = [root + '/dlprod_192px_0{}.root'.format(i) for i in range(8)]\n",
    "devset = [root + '/dlprod_192px_0{}.root'.format(8)]\n",
    "testset = [root + '/dlprod_192px_0{}.root'.format(9)]\n",
    "print(trainset)\n",
    "print(devset)\n",
    "print(testset)\n",
    "trainset = ClusteringAEData(root, 192, filenames=trainset)\n",
    "devset = ClusteringAEData(root, 192, filenames=devset)\n",
    "testset = ClusteringAEData(root, 192, filenames=testset)\n",
    "print('Number of entries in training set: {}'.format(len(trainset)))\n",
    "print('Number of entries in validation set: {}'.format(len(devset)))\n",
    "print('Number of entries in test set: {}'.format(len(testset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(trainset, batch_size=32, shuffle=True, collate_fn=ae_collate, num_workers=1, pin_memory=False)\n",
    "devloader = DataLoader(devset, batch_size=64, shuffle=True, collate_fn=ae_collate, num_workers=1, pin_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape = torch.Size([3827, 3])\n",
      "y.shape = torch.Size([3827, 1])\n",
      "labels.shape = (3827,)\n",
      "[0. 2.]\n"
     ]
    }
   ],
   "source": [
    "x, y = trainset[0][0]\n",
    "print(\"X.shape = {}\".format(x.shape))\n",
    "print(\"y.shape = {}\".format(y.shape))\n",
    "labels = trainset[0][1]\n",
    "print(\"labels.shape = {}\".format(labels.shape))\n",
    "print(np.unique(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, each row of 'coords' is the x,y,z coordinates of the active pixels of the 3D tensor, and each row of 'y' is the value of the pixel at the corresponding 'coords' coordinates. That is, at (97, 42, 5) we have pixel value 0.0156. This notation is called a Sparse Representation since it only gives the active pixel sites for a large sparse matrix. Here, there are only two clusters, since np.unique(labels) gives 0 and 2, which are the integer labels of the clusters. We have one label per pixel site. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: \n",
    "### 1. Make 3D Visualization for Sparse Matrices\n",
    "### 2. Run DBSCAN on each cluster example and see how it performs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Architectures for Autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseUResNet(torch.nn.Module):\n",
    "    def __init__(self, dimension=3, size=192, nFeatures=16, depth=5, nClasses=1):\n",
    "        super(SparseUResNet, self).__init__()\n",
    "        self.dimension = dimension\n",
    "        self.size = size\n",
    "        self.nFeatures = nFeatures\n",
    "        self.depth = depth\n",
    "        self.nClasses = nClasses\n",
    "        reps = 2  # Conv block repetition factor\n",
    "        kernel_size = 2  # Use input_spatial_size method for other values?\n",
    "        m = nFeatures  # Unet number of features\n",
    "        nPlanes = [i*m for i in range(1, depth+1)]  # UNet number of features per level\n",
    "        nInputFeatures = 1\n",
    "        # From Submanifold Sparse Convnet Github Repo by Benjamin Graham.\n",
    "        self.sparseModel = scn.Sequential().add(\n",
    "           scn.InputLayer(dimension, size, mode=3)).add(\n",
    "           scn.SubmanifoldConvolution(dimension, nInputFeatures, m, 3, False)).add( # Kernel size 3, no bias\n",
    "           scn.UNet(dimension, reps, nPlanes, residual_blocks=True, downsample=[kernel_size, 2])).add(  # downsample = [filter size, filter stride]\n",
    "           scn.BatchNormReLU(m)).add(\n",
    "           scn.OutputLayer(dimension))\n",
    "        self.linear = torch.nn.Linear(m, nClasses)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x is scn coordinate, feature input\n",
    "        \"\"\"\n",
    "        x = self.sparseModel(x)\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LArCVEncoder(nn.Module):\n",
    "    def __init__(self, dim=3, size=192, nFeatures=16, depth=5, nClasses=1, leakiness=0):\n",
    "        super(LArCVEncoder, self).__init__()\n",
    "\n",
    "        nIn = nFeatures\n",
    "        nOut = nIn * 2\n",
    "        self.convLayers = []\n",
    "        self.convPoolLayers = []\n",
    "        self.bnReLUs = []\n",
    "        \n",
    "        self.inputLayer = scn.InputLayer(dim, size, mode=3)\n",
    "        self.convLayers.append(scn.Convolution(dim, 1, nIn, 3, 1, False))\n",
    "        self.bnReLUs.append(scn.BatchNormLeakyReLU(nIn))\n",
    "        self.convPoolLayers.append(scn.Convolution(dim, nIn, nIn, 2, 2, False))\n",
    "        for _ in range(5):\n",
    "            self.convLayers.append(\n",
    "                scn.SubmanifoldConvolution(dim, nIn, nOut, 3, False))\n",
    "            self.bnReLUs.append(scn.BatchNormLeakyReLU(nOut))\n",
    "            self.convPoolLayers.append(\n",
    "                scn.Convolution(dim, nOut, nOut, 2, 2, False))\n",
    "            nIn = nOut\n",
    "            nOut = nIn * 2\n",
    "        self.convLayers.append(scn.Convolution(dim, nIn, nOut, 3, 1, False))\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x is scn coordinate, feature input\n",
    "        \"\"\"\n",
    "        x = self.inputLayer(x)\n",
    "        for i in range(len(self.bnReLUs)):\n",
    "            x = self.convLayers[i](x)\n",
    "            print('-' * 20)\n",
    "            print(x)\n",
    "            x = self.bnReLUs[i](x)\n",
    "            print('-' * 20)\n",
    "            print(x)\n",
    "            x = self.convPoolLayers[i](x)\n",
    "            print('-' * 20)\n",
    "            print(x)\n",
    "        x = self.convLayers[-1](x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LArCVEncoder()\n",
    "model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, optimizer, epochs, loss_fn=nn.MSELoss(), use_cuda=False, log=2):\n",
    "    \"\"\"\n",
    "    Function for training SparseUResNet.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    iteration = 0\n",
    "    for ep in range(epochs):\n",
    "        minibatch = torch.zeros\n",
    "        for batch_idx, entry in enumerate(loader):\n",
    "            data, label = entry\n",
    "            optimizer.zero_grad()\n",
    "            batch_ids = [torch.ones((t[0].shape[0], 1),\n",
    "                dtype=torch.long) * batch_idx for t in data]\n",
    "            coords = [torch.cat([t[0], batch_ids[i]], dim=1) \n",
    "                for i, t in enumerate(data)]\n",
    "            coords = torch.cat(coords, dim=0)\n",
    "            energy = [t[1] for t in data]\n",
    "            values = torch.cat(energy, dim=0)\n",
    "            if use_cuda:\n",
    "                coords, values = coords.cuda(), values.cuda()\n",
    "            out = model((coords, values))\n",
    "            loss = loss_fn.forward(out, values)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if iteration % log == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    ep, batch_idx * len(label), len(loader.dataset),\n",
    "                    100. * batch_idx / len(loader), loss.item()))\n",
    "            iteration += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = {}\n",
    "p['n_epochs'] = 100\n",
    "p['initial_lr'] = 1e-1\n",
    "p['lr_decay'] = 4e-2\n",
    "p['weight_decay'] = 1e-4\n",
    "p['momentum'] = 0.9\n",
    "p['check_point'] = False\n",
    "p['use_cuda'] = torch.cuda.is_available()\n",
    "\n",
    "model = SparseUResNet()\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "if p['use_cuda']:\n",
    "    model.cuda()\n",
    "    criterion.cuda()\n",
    "optimizer = optim.SGD(model.parameters(),\n",
    "    lr=p['initial_lr'],\n",
    "    momentum=p['momentum'],\n",
    "    weight_decay=p['weight_decay'],\n",
    "    nesterov=True)\n",
    "\n",
    "train(model, trainloader, optimizer, 1, loss_fn=criterion, use_cuda=use_cuda, log=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxels, energy, labels = ireader.get_image(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.ones(t[0].shape[0], 1, dtype=torch.long) * 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images\n",
    "coords = [torch.cat([t[0], torch.ones(t[0].shape[0], 1, dtype=torch.long) * i], dim=1) for i, t in enumerate(images)]\n",
    "coords = torch.cat(coords, dim=0)\n",
    "print(coords, coords.shape)\n",
    "values = torch.cat([t[1] for t in images], dim=0)\n",
    "print(values, values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords, values = coords.cuda(), values.cuda()\n",
    "data = (coords, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = out - data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "criterion.forward(out, data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_id = torch.ones((voxels.shape[0], 1), dtype=torch.long) * 1\n",
    "print(batch_id)\n",
    "data = coords\n",
    "x = (data, y)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SparseUResNet(3, 192, 16, 5)\n",
    "root = '/gpfs/slac/staas/fs1/g/neutrino/kterao/data/dlprod_ppn_v10'\n",
    "dataset = ClusteringAEData(root, 192)\n",
    "loader = DataLoader(dataset, batch_size=64, shuffle=True, \n",
    "                    collate_fn=ae_collate, num_workers=1)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "p = {}\n",
    "p['n_epochs'] = 100\n",
    "p['initial_lr'] = 1e-1\n",
    "p['lr_decay'] = 4e-2\n",
    "p['weight_decay'] = 1e-4\n",
    "p['momentum'] = 0.9\n",
    "p['check_point'] = False\n",
    "p['use_cuda'] = torch.cuda.is_available()\n",
    "\n",
    "if p['use_cuda']:\n",
    "    model.cuda()\n",
    "    criterion.cuda()\n",
    "optimizer = optim.SGD(model.parameters(),\n",
    "    lr=p['initial_lr'],\n",
    "    momentum=p['momentum'],\n",
    "    weight_decay=p['weight_decay'],\n",
    "    nesterov=True)\n",
    "\n",
    "dtype = 'torch.cuda.FloatTensor' if p['use_cuda'] else 'torch.FloatTensor'\n",
    "dtypei = 'torch.cuda.LongTensor' if p['use_cuda'] else 'torch.LongTensor'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
